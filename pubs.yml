---
name: Refereed Publications
hugoid: 7
urlid: ref
pubs: 
    - c23:
        authors:
            - jspjut
            - bboudaoud
            - joohwankim
        title: A Case Study of First Person Aiming at Low Latency for Esports
        conference: Esports and High-Performance Human-Computer Interaction Workshop
        conf-short: EHPHCI
        month: May 8
        year: 2021
        date: 2021-05-08
        paper: https://osf.io/nu9p3/
        alternate: https://research.nvidia.com/publication/2021-05_A-Case-Study
        abstract: "Lower computer system input-to-output latency substantially re-duces many task completion times. In fact, literature shows that reduction in targeting task completion time from decreased latency often exceeds the decrease in latency alone. However, for aiming in first person shooter (FPS) games, some prior work has demonstrated diminishing returns below 40 ms of local input-to-output computer system latency. In this paper, we review this prior art and provide an additional case study with data demonstrating the importance of local system latency improvement, even at latency values below 20 ms. Though other factors may determine victory in a particular esports challenge, ensuring balanced local computer latency among competitors is essential to fair competition."
        thumbnail: spjut21ehphci.png
        banner: spjut21ehphci.png
    - c22:
        authors:
            - zmajercik
            - amarrs
            - jspjut
            - mmcguire
        title: "Scaling Probe-Based Real-Time Dynamic Global Illumination for Production"
        conference: The Journal of Computer Graphics Techniques
        conf-short: JCGT
        month: May 3
        year: 2021
        date: 2021-05-03
        paper: http://jcgt.org/published/0010/02/01/
        abstract: 'We contribute several practical extensions to the probe-based irradiance-field-with-visibility representation [Majercik et al. 2019] [McGuire et al. 2017] to improve image quality, constant and asymptotic performance, memory efficiency, and artist control. We developed these extensions in the process of incorporating the previous work into the global illumination solutions of the NVIDIA RTXGI SDK, the Unity and Unreal Engine 4 game engines, and proprietary engines for several commercial games. These extensions include: an intuitive tuning parameter (the "self-shadow" bias); heuristics to speed transitions in the global illumination; reuse of irradiance data as prefiltered radiance for recursive glossy reflection; a probe state machine to prune work that will not affect the final image; and multiresolution cascaded volumes for large worlds.'
        thumbnail: majercik21.png
        banner: majercik21.png
    - c21:
        authors:
            - joohwankim
            - pknowles
            - jspjut
            - bboudaoud
            - mmcguire
        title: "Post-Render Warp with Late Input Sampling Improves Aiming Under High Latency Conditions"
        conference: Proceedings of the ACM on Computer Graphics and Interactive Techniques
        conf-short: PACM CGIT
        month: July 13-16
        year: 2020
        date: 2020-07-13
        paper: http://josef.spjut.me/pubs/kim_hpg2020_author.pdf
        alternate: https://research.nvidia.com/publication/2020-07_Post-Render-Warp-with
        alternate2: https://doi.org/10.1145/3406187
        abstract: "End-to-end latency in remote-rendering systems can reduce user task performance. This notably includes aiming tasks on game streaming services, which are presently below the standards of competitive first-person desktop gaming. We evaluate the latency-induced penalty on task completion time in a controlled environment and show that it can be significantly mitigated by adopting and modifying image and simulation-warping techniques from virtual reality, eliminating up to 80% of the penalty from 80 ms of added latency. This has potential to enable remote rendering for esports and increase the effectiveness of remote-rendered content creation and robotic teleoperation. We provide full experimental methodology, analysis, implementation details, and source code."
        thumbnail: kimhpg20.png
        banner: kimhpg20.png
    - c20:
        authors:
            - jspjut
            - bboudaoud
            - jonghyunkim
            - tgreer
            - ralbert
            - mstengel
            - kaksit
            - dluebke
        title: "Toward Standardized Classification of Foveated Displays"
        conference: IEEE Transactions on Visualization and Computer Graphics
        conf-short: TVCG
        month: March 22
        year: 2020
        date: 2020-03-22
        paper: https://ieeexplore.ieee.org/document/8999630
        alternate: https://arxiv.org/abs/1905.06229
        alternate2: https://doi.org/10.1109/TVCG.2020.2973053
        abstract: "Emergent in the field of head mounted display design is a desire to leverage the limitations of the human visual system to reduce the computation, communication, and display workload in power and form-factor constrained systems. Fundamental to this reduced workload is the ability to match display resolution to the acuity of the human visual system, along with a resulting need to follow the gaze of the eye as it moves, a process referred to as foveation. A display that moves its content along with the eye may be called a Foveated Display, though this term is also commonly used to describe displays with non-uniform resolution that attempt to mimic human visual acuity. We therefore recommend a definition for the term Foveated Display that accepts both of these interpretations. Furthermore, we include a simplified model for human visual Acuity Distribution Functions (ADFs) at various levels of visual acuity, across wide fields of view and propose comparison of this ADF with the Resolution Distribution Function of a foveated display for evaluation of its resolution at a particular gaze direction. We also provide a taxonomy to allow the field to meaningfully compare and contrast various aspects of foveated displays in a display and optical technology-agnostic manner."
        thumbnail: spjutvr20.png
        banner: spjutvr20.png
    - c19:
        authors:
            - jspjut
            - bboudaoud
            - kbinaee
            - jonghyunkim
            - zmajercik
            - mmcguire
            - dluebke
            - joohwankim
        title: "Latency of 30 ms Benefits First Person Targeting Tasks More Than Refresh Rate Above 60 Hz"
        conference: SIGGRAPH Asia Technical Briefs
        conf-short: SA'19 Technical Briefs
        month: November 17-20
        year: 2019
        date: 2019-11-17
        paper: https://research.nvidia.com/publication/2019-11_Latency-of-30
        alternate: https://dl.acm.org/citation.cfm?id=3365170
        alternate2: https://research.nvidia.com/sites/default/files/pubs/2019-11_Latency-of-30/FPS_Tasks_sa2019_AuthorVersion.pdf
        abstract: "In competitive sports, human performance makes the difference between who wins and loses. In some competitive video games (esports), response time is an essential factor of human performance. When the athlete's equipment (computer, input and output device) responds with lower latency, it provides a measurable advantage. In this study, we isolate latency and refresh rate by artificially increasing latency when operating at high refresh rates. Eight skilled esports athletes then perform gaming-inspired first person targeting tasks under varying conditions of refresh rate and latency, completing the tasks as quickly as possible. We show that reduced latency has a clear benefit in task completion time while increased refresh rate has relatively minor effects on performance when the inherent latency reduction present at high refresh rates is removed. Additionally, for certain tracking tasks, there is a small, but marginally significant effect from high refresh rates alone."
        thumbnail: spjut19-sa.png
        banner: spjut19-sa.png
    - c18:
        authors:
            - clarson
            - jspjut
            - rknepper
            - rshepherd
        title: "A deformable interface for human touch recognition using stretchable carbon nanotube dielectric elastomer sensors and deep neural networks"
        conference: Soft Robotics
        conf-short: SoRo
        month: October 4
        year: 2019
        date: 2019-10-04
        paper: https://www.liebertpub.com/doi/pdf/10.1089/soro.2018.0086
        alternate: https://www.liebertpub.com/doi/full/10.1089/soro.2018.0086
        abstract: "This article presents a machine learning approach to map outputs from an embedded array of sensors distributed throughout a deformable body to continuous and discrete virtual states, and its application to interpret human touch in soft interfaces. We integrate stretchable capacitors into a rubber membrane, and use a passive addressing scheme to probe sensor arrays in real time. To process the signals from this array, we feed capacitor measurements into convolutional neural networks that classify and localize touch events on the interface. We implement this concept with a device called OrbTouch. To modularize the system, we use a supervised learning approach wherein a user defines a set of touch inputs and trains the interface by giving it examples; we demonstrate this by using OrbTouch to play the popular game Tetris. Our regression model localizes touches with mean test error of 0.09 mm, whereas our classifier recognizes five gestures with a mean test error of 1.2%. In a separate demonstration, we show that OrbTouch can discriminate between 10 different users with a mean test error of 2.4%. At test time, we feed the outputs of these models into a debouncing algorithm to provide a nearly error-free experience."
        thumbnail: clarson19.png
        banner: clarson19.png
    - c16:
        authors:
            - jonghyunkim
            - youngmojeong
            - mstengel
            - kaksit
            - ralbert
            - wlopes
            - tgreer
            - bboudaoud
            - zmajercik
            - jspjut
            - mmcguire
            - dluebke
        title: "Foveated AR: Dynamically-Foveated Augmented Reality Display"
        conference: ACM SIGGRAPH Proceedings
        conf-short: SIGGRAPH
        location: Los Angeles
        month: July
        year: 2019
        date: 2019-07-28
        paper: https://research.nvidia.com/sites/default/files/pubs/2019-07_Foveated-AR%3A-Dynamically-Foveated//Foveated_AR___v2%20%2815%29.pdf
        alternate: https://research.nvidia.com/publication/2019-07_Foveated-AR%3A-Dynamically-Foveated
        abstract: "We present a near-eye augmented reality display with resolution and focal depth dynamically driven by gaze tracking. The display combines a traveling microdisplay relayed off a concave half-mirror magnifier for the high-resolution foveal region, with a wide field-of-view peripheral display using a projector-based Maxwellian-view display whose nodal point is translated to follow the viewer's pupil during eye movements using a traveling holographic optical element.  The same optics relay an image of the eye to an infrared camera used for gaze tracking, which in turn drives the foveal display location and peripheral nodal point. Our display supports accommodation cues by varying the focal depth of the microdisplay in the foveal region, and by rendering simulated defocus on the 'always in focus' scanning laser projector used for peripheral display. The resulting family of displays significantly improves on the field-of-view, resolution, and form-factor tradeoff present in previous augmented reality designs.  We show prototypes supporting 30, 40 and 60 cpd foveal resolution at a net 85x78 degree field of view per eye."
        thumbnail: jkim19-foveatedar.png
        banner: jkim19-foveatedar.png
    - c17:
        authors:
            - pandersson
            - jnilsson
            - msalvi
            - jspjut
            - takeninemoller
        title: "Temporally Dense Ray Tracing"
        conference: High Performance Graphics
        conf-short: HPG
        location: Strasbourg
        month: July 8
        year: 2019
        date: 2019-07-08
        paper: https://research.nvidia.com/sites/default/files/pubs/2019-07_Temporally-Dense-Ray/temporally-dense-ray-tracing.pdf
        alternate: https://research.nvidia.com/publication/2019-07_Temporally-Dense-Ray
        abstract: "We present a technique for real-time ray tracing with the goal of reaching 240 frames per second or more. The core idea is to trade spatial resolution for faster temporal updates in such a way that the display and human visual system aid in integrating high-quality images. We use a combination of frameless and interleaved rendering concepts together with ideas from temporal antialiasing algorithms and novel building blocks---the major one being adaptive selection of pixel orderings within tiles, which reduces spatiotemporal aliasing significantly. The image quality is verified with a user study. Our work can be used for esports or any kind of rendering where higher frame rates are needed."
        thumbnail: andersson19.png
        banner: andersson19.png
        webpage: https://240hz.org/
    - c15:
        authors:
            - mjalal
            - jspjut
            - bboudaoud
            - mbetke
        title: "SIDOD: A Synthetic Image Dataset for 3D Object Pose Recognition with Distractors"
        conference: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops
        conf-short: WiCV
        location: Long Beach
        month: June 16
        year: 2019
        date: 2019-06-16
        paper: http://openaccess.thecvf.com/content_CVPRW_2019/papers/WiCV/Jalal_SIDOD_A_Synthetic_Image_Dataset_for_3D_Object_Pose_Recognition_CVPRW_2019_paper.pdf
        alternate: https://research.nvidia.com/publication/2019-06_SIDOD%3A-A-Synthetic
        alternate2: http://openaccess.thecvf.com/content_CVPRW_2019/html/WiCV/Jalal_SIDOD_A_Synthetic_Image_Dataset_for_3D_Object_Pose_Recognition_CVPRW_2019_paper.html
        abstract: "We present a new image dataset generated by the NVIDIA Deep Learning Data Synthesizer intended for use in object detection, pose estimation, and tracking applications. This dataset contains 144k stereo image pairs generated from 18 camera view points of three photorealistic virtual environments with up to 10 objects (chosen randomly from the 21 object models of the YCB dataset) and flying distractors.  Object and camera pose, scene lighting, and quantity of objects and distractors were randomized. Each provided view includes RGB, depth, segmentation, and surface normal images. We describe our approach for domain randomization and provide insight into the decisions that produced the dataset."
        thumbnail: jalal19.png
        banner: jalal19.png
    - c14:
        authors:
            - jbarreiros
            - hclaure
            - bpeele
            - oshapira
            - jspjut
            - dluebke
            - mjung
            - rshepherd
        title: Fluidic Elastomer Actuators for Haptic Interactions in Virtual Reality
        conference: IEEE Robotics and Automation Letters (RA-L)
        conf-short: IEEE RA-L
        location: 
        month: February
        year: 2019
        date: 2019-02-27
        paper: https://ieeexplore.ieee.org/abstract/document/8581471
        abstract: "Virtual reality experiences via immersive optics and sound are becoming ubiquitous; there are several consumer systems (e.g., Oculus Rift and HTC Vive) now available with these capabilities. Other sensory experiences, such as that of touch remain elusive in this field. The most successful examples of haptic sensation (e.g., Nintendo 64's rumble pack and its descendants) are vibrotactile, which do not afford for persistent, morphological shape experiences. This letter presents work on the development of a 12 DOF fluidically pressurized soft actuator for persistent and kinesthetic haptic sensations, a hardware controller for operating it, and software interface with NVIDIA's game VR Funhouse."
        thumbnail: barreiros19.png
        banner: barreiros19.png
    - c13:
        authors:
            - amarrs
            - jspjut
            - hgruen
            - rsathe
            - mmcguire
        title: Adaptive Temporal Antialiasing
        conference: High-Performance Graphics (HPG 2018)
        conf-short: HPG
        location: Vancouver
        month: August 10-12
        year: 2018
        date: 2018-08-10
        paper: http://research.nvidia.com/sites/default/files/pubs/2018-08_Adaptive-Temporal-Antialiasing/adaptive-temporal-antialiasing-preprint.pdf
        alternate: http://research.nvidia.com/publication/2018-08_Adaptive-Temporal-Antialiasing
        abstract: We introduce a pragmatic algorithm for real-time adaptive supersampling in games. It extends temporal antialiasing of rasterized images with adaptive ray tracing, and conforms to the constraints of a commercial game engine and today's GPU ray tracing APIs. The algorithm removes blurring and ghosting artifacts associated with standard temporal antialiasing and achieves quality approaching 8X supersampling of geometry, shading, and materials while staying within the 33ms frame budget required of most games.
        thumbnail: marrs18a.png
        banner: marrs18a.png
    - c12:
        authors:
            - kshkurko
            - tgrant
            - elb
            - dkopta
            - jspjut
            - evasiou
            - imallett
            - cyuksel
        title: "SimTrax: Simulation Infrastructure for Exploring Thousands of Cores"
        conference: ACM Great Lakes Symposium on VLSI
        conf-short: GLSVLSI
        month: May 23-25
        year: 2018
        date: 2018-05-23
        paper: http://josef.spjut.me/pubs/shkurko18.pdf
        abstract: "SimTRaX is a simulation infrastructure for simultaneous exploration of highly parallel accelerator architectures and how applications map to them. The infrastructure targets both cycle-accurate and functional simulation of architectures with thousands of simple cores that may share expensive computation and memory resources. A modified LLVM backend used to compile C++ programs for the simulated architecture allows the user to create custom instructions that access proposed special-purpose hardware and to debug and profile the applications being executed. The simulator models a full memory hierarchy including registers, local scratchpad RAM, shared caches, external memory channels, and DRAM main memory, leveraging the USIMM DRAM simulator to provide accurate dynamic latencies and power usage. SimTRaX provides a powerful and flexible infrastructure for exploring a class of extremely parallel architectures for parallel applications that are not easily simulated using existing simulators."
        thumbnail: shkurko18.png
        banner: shkurko18.png
    - c11:
        authors:
        - bmacmurray
        - bpeele
        - patriciaxu
        - jspjut
        - oshapira
        - dluebke
        - rshepherd
        title: A Variable Shape and Variable Stiffness Controller for Haptic Virtual Interactions
        conference:  IEEE International Conference on Soft Robotics
        conf-short: RoboSoft
        month: April 24-28
        year: 2018
        date: 2018-04-24
        paper: http://research.nvidia.com/sites/default/files/pubs/2018-04_A-Variable-Shape/Mac%20Murray%20Final%2020180228.pdf
        abstract: "This paper presents an entirely compliant controller handle for use in virtual and augmented reality environments. The controller handle transitions between two static states: a semi-rigid, large diameter state when pneumatically pressurized and a soft, compressible, smaller diameter state when depressurized. We integrated the controller with a modified version of NVIDIA’s VR Funhouse employing the two controller states to simulate the physical feel of two virtual objects. We used finite element modeling to downselect an internal elastomer lattice within the controller that controls deformation upon inflation. Finally, we show an example of using the compliance of the handle as an interaction input by designing an algorithm to identify rapid compressions of the handle as a signal to swap objects in the virtual environment."
        alternate: http://research.nvidia.com/publication/2018-04_A-Variable-Shape
        thumbnail: robosoft2018.png
        banner: macmurray18.png
    - c10:
        authors:
        - tgreer
        - jspjut
        - dluebke
        - jtw
        title: Hybrid Modulation for Near Zero Display Latency
        conference: Society of Information Display
        conf-short: SID
        month: May 24-27
        year: 2016
        date: 2016-05-24
        paper: http://josef.spjut.me/pubs/greer16.pdf
        alternate: http://onlinelibrary.wiley.com/doi/10.1002/sdtp.10614/full
        video: https://www.youtube.com/watch?v=BKzXRwJ8gjw
        abstract: "Binary displays for virtual reality can achieve low latency by integrating view tracking with modulation. We present a novel modulation scheme that combines tracking, pulse density modulation, and pulse width modulation to minimize grayscale artifacts. The hybrid modulator is applied to an AMOLED display at an update rate of 1.7 kHz on which we observe nearly zero latency in the perceived image."
        thumbnail: greer16.png
        banner: greer16.png
    - c9:
        authors:
        - dkopta
        - kshkurko
        - jspjut
        - elb
        - ald
        title: Memory Considerations for Low Energy Ray Tracing
        conference: Computer Graphics Forum
        conf-short: CGF
        month: August 7
        year: 2014
        date: 2014-08-07
        paper: http://onlinelibrary.wiley.com/doi/10.1111/cgf.12458/abstract?systemMessage=Wiley+Online+Library+will+be+disrupted+9th+Aug+from+10-2+BST+for+essential+maintenance.+Pay+Per+View+will+be+unavailable+from+10-6+BST.
        thumbnail: kopta14.png
        banner: kopta14.png
    - c8:
        authors:
        - dkopta
        - kshkurko
        - jspjut
        - elb
        - ald
        title: An Energy and Bandwidth Efficient Ray Tracing Architecture
        conference: High-Performance Graphics (HPG 2013)
        conf-short: HPG
        location: Anaheim
        month: July 10-21
        year: 2013
        date: 2013-07-10
        paper: http://www.cs.utah.edu/~dkopta/papers/hwrt_hpg13.pdf
        thumbnail: kopta13.png
        banner: kopta13.png
    - c7:
        authors:
        - dkopta
        - tize
        - jspjut
        - elb
        - ald
        - aek
        title: 'Fast, Effective BVH Updates for Animated Scenes'
        conference: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D 2012)
        conf-short: I3D
        location: Irvine
        month: March 
        year: 2012
        date: 2012-03-01
        paper: http://www.cs.utah.edu/~thiago/papers/rotations.pdf
        thumbnail: kopta12.png
        banner: kopta12.png
    - c6:
        authors:
        - jspjut
        - dkopta
        - elb
        - ald
        title: A Mobile Accelerator Architecture for Ray Tracing
        conference: '3rd Workshop on SoCs, Heterogeneous Architectures and Workloads (SHAW-3)'
        conf-short: SHAW
        location: New Orleans
        month: February 
        year: 2012
        date: 2012-02-01
        paper: http://www.cs.utah.edu/~sjosef/papers/spjut-shaw12-final.pdf
        slides: http://www.cs.utah.edu/~sjosef/slides/spjut-shaw12-slides.pdf
        thumbnail: spjut12.png
        banner: spjut12.png
    - c5:
        authors:
        - dkopta
        - jspjut
        - ald
        - elb
        title: Efficient MIMD Architectures for High-Performance Ray Tracing
        conference: IEEE International Conference on Computer Design (ICCD 2010)
        conf-short: ICCD
        location: Amsterdam
        month: October 
        year: 2010
        date: 2010-10-01
        paper: http://www.cs.utah.edu/~dkopta/papers/hwrt_iccd10.pdf
        thumbnail: kopta10.png
    - c4:
        authors:
        - spugsley
        - jspjut
        - dnellans
        - rajeev
        title: 'SWEL: Hardware Cache Coherence Protocols to Map Shared Data onto Shared Caches'
        conference: 19th International Conference on Parallel Architectures and Compilation Techniques (PACT-19)
        conf-short: PACT
        location: Vienna
        month: September 
        year: 2010
        date: 2010-09-01
        paper: https://pdfs.semanticscholar.org/ce47/02c907835c14022c9e3052a25c46d459c295.pdf
        thumbnail: pugsley10.png
    - c3: 
        authors:
        - jspjut
        - aek
        - dkopta
        - elb
        title: 'TRaX: A Multicore Architecture for Real-Time Ray Tracing'
        conference: IEEE Transactions on Computer Aided Design of Integrated Circuits and Systems (TCAD)
        conf-short: TCAD
        month: December
        year: 2009
        date: 2009-12-01
        paper: http://www.cs.utah.edu/~dkopta/papers/hwrt_tcad09.pdf
        thumbnail: spjut_tcad09.png
    - c2:
        authors:
        - jspjut
        - aek 
        - elb
        title: Hardware-accelerated gradient noise for graphics
        conference: Proceedings of the 19th ACM Great Lakes Symposium on VLSI (GLSVLSI'09)
        conf-short: GLSVLSI
        location: Boston
        month: May 10-12
        year: 2009
        date: 2009-05-10
        paper: http://www.eng.utah.edu/~cs6958/papers/noise.pdf
        thumbnail: spjut_glsvlsi09.png
    - c1: 
        authors: 
        - nil
        - spugsley
        - jspjut 
        - rajeev
        title: Optimizing a Multi-Core Processor for Message-Passing Workloads
        conference: 5th Workshop on Unique Chips and Systems (UCAS-5)
        conf-short: UCAS
        location: Boston
        month: April
        year: 2009
        date: 2009-04-01
        paper: http://ai2-s2-pdfs.s3.amazonaws.com/f87a/bd4bf77bae5286fbde62de6b331d45c30d0c.pdf
        thumbnail: nil09.png
    - c0: 
        authors: 
        - jspjut 
        - sboulos 
        - dkopta 
        - elb 
        - skellis
        title: "TRaX: A Multi-Threaded Architecture for Real-Time Ray Tracing"
        conference: "Symposium on Application Specific Processors (SASP)"
        conf-short: SASP
        location: Anaheim
        month: June 8-9
        year: 2008
        date: 2008-06-08
        misc: (Best paper award)
        paper: http://www.cs.utah.edu/~dkopta/papers/hwrt_sasp08.pdf
        thumbnail: spjut08.png
---
name: Book Chapter
hugoid: 6
urlid: bc
pubs:
    - bc2:
        authors:
        - rsathe
        - hgruen
        - amarrs
        - jspjut
        - mmcguire
        - yyuralsky
        title: "Adaptive Anti-Aliasing using Conservative Rasterization and GPU Ray Tracing"
        conference: GPU Zen 2
        conf-short: GPU Zen 2
        month: April
        year: 2019
        date: 2019-04-21
        paper: https://www.amazon.com/dp/179758314X
        thumbnail: sathe19.png
        banner: none.png
        abstract: 
    - bc1:
        authors:
        - amarrs
        - jspjut
        - hgruen
        - rsathe
        - mmcguire
        title: Improving Temporal Antialiasing with Adaptive Ray Tracing
        conference: Ray Tracing Gems
        conf-short: RTG
        month: March
        year: 2019
        date: 2019-03-31
        paper: https://link.springer.com/content/pdf/10.1007%2F978-1-4842-4427-2_22.pdf
        alternate: https://research.nvidia.com/publication/2019-03_Improving-Temporal-Antialiasing
        alternate2: https://developer.nvidia.com/books/raytracing/raytracing_gems_preview
        thumbnail: ATAA_RTG19.png
        banner: ATAA_RTG19.png
        abstract: In this chapter, we discuss a pragmatic approach to real-time supersampling that extends commonly used temporal antialiasing techniques with adaptive ray tracing. The algorithm conforms to the constraints of a commercial game engine, removes blurring and ghosting artifacts associated with standard temporal antialiasing, and achieves quality approaching 16x supersampling of geometry, shading, and materials within the 16 ms frame budget required of most games.
---
name: Technical Demos
hugoid: 8
urlid: td
pubs:
    - td5:
        authors:
        - bboudaoud
        - pknowles
        - joohwankim
        - jspjut
        title: "Gaming at Warp Speed: Improving Aiming with Late Warp"
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: online
        month: August 9-13
        year: 2021
        date: 2021-08-09
        paper: https://research.nvidia.com/publication/2021-08_Gaming-at-Warp
        thumbnail: boudaoud21etech.png
        banner: boudaoud21etech.png
        abstract: Latency can make all the difference in competitive online games. Late warp is a class of techniques used in VR that can reduce latency in FPS games as well. Prior art has demonstrated these techniques can recover most of the player performance lost to computer or network latency. Inspired by prior work demonstrating the usefulness of late warp as a potential solution to FPS latency, we provide an interactive demonstration, playable in a web browser, that shows how much latency limits aiming performance, and how late warp can help.
    - td4:
        authors:
        - jonghyunkim
        - mstengel
        - juiyiwu
        - bboudaoud
        - jspjut
        - kaksit
        - ralbert
        - tgreer
        - youngmojeong
        - wlopes
        - zmajercik
        - pshirley
        - mmcguire
        - dluebke
        title: "Matching Visual Acuity & Prescription: Towards AR for Humans"
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: Los Angeles
        month: July 28 - August 1
        year: 2019
        date: 2019-07-28
        paper: https://research.nvidia.com/sites/default/files/pubs/2019-07_Matching-Prescription-%26//2019_Etech_submission%20%2815%29.pdf
        alternate: https://research.nvidia.com/publication/2019-07_Matching-Prescription-%26
        thumbnail: etech19.png
        banner: etech19.png
        abstract: "In this installation, we demonstrate two novel wearable augmented reality (AR) prototypes inspired by the understandings on human visual system: Prescription AR and Foveated AR. Prescription AR is a 5mm-thick prescription-embedded AR display based on a free-form image combiner. A plastic prescription lens corrects viewer's vision while a half-mirror-coated free-form image combiner located delivers an augmented image located at the fixed focal depth (1 m). Foveated AR is a near-eye AR display with resolution and focal depth dynamically driven by gaze tracking. The display combines a traveling microdisplay relayed off a concave half-mirror magnifier for the high-resolution foveal region, with a wide FOV peripheral display using a projector-based Maxwellian-view display whose nodal point is translated to follow the viewer's pupil during eye movements using a traveling holographic optical element (HOE). The same optics relay an image of the eye to an infrared camera used for gaze tracking, which in turn drives the foveal display location and peripheral nodal point. Our display supports accommodation cues by varying the focal depth of the microdisplay in the foveal region, and by rendering simulated defocus on the 'always in focus' scanning laser projector used for peripheral display."
    - td3:
        authors:
        - krathinavel
        - pchakravarthula
        - kaksit
        - jspjut
        - bboudaoud
        - jtw
        - dluebke
        - hfuchs
        title: "Steerable Application-Adaptive Near-Eye Displays"
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: Vancouver
        month: August 12 - 16
        year: 2018
        date: 2018-08-12
        misc: (Best in show award)
        paper: https://kaanaksit.com/portfolio/manufacturing-application-driven-near-eye-displays/
        thumbnail: etech18-unc.png
        banner: etech18-unc.png
        abstract: This augmented reality display uses interchangeable 3D-printed optical components to provide content-specific accommodation support. It also presents high-resolution imagery in a gaze-contingent manner by implementing a lens actuation based foveation mechanism.
    - td2:
        authors:
        - kaksit
        - wlopes
        - jonghyunkim
        - jspjut
        - apatney
        - pshirley
        - dluebke
        - scholewiak
        - psrinivasan
        - renng
        - mbanks
        - glove
        title: "Varifocal Virtuality: A Novel Optical Layout for Near-Eye Display"
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: Los Angeles
        month: July 30 - August 3
        year: 2017
        date: 2017-07-30
        paper: http://research.nvidia.com/sites/default/files/publications/final%281%29.pdf
        alternate: http://research.nvidia.com/publication/2017-07_Varifocal-Virtuality%3A-A
        slides: https://kaanaksit.files.wordpress.com/2017/08/siggraph_slides.pdf
        thumbnail: etech17-nv.png
        banner: etech17-nv.png
        abstract: Augmented reality (AR) has recently gained momentum in the form of a variety of available optical see-through near-eye displays (NEDs) such as the Meta 2and the Microsoft Hololens. These devices are a big step forward towards Sutherland's vision of an ultimate display [Sutherland 1968]. The device we demonstrate attempts to deal with the main limitations of current devices. First, the graphics images are at a constant virtual distance for the eyes' accommodation mechanism, while the vergence of the two eyes working in concert places the virtual object(s) at a distance other than the accommodation distance. This vergence-accommodation conflict is one of the main problems in many AR and VR systems [Kress and Starner 2013]. The second limitation is achieving a wide FOV with compact optics. Cakmakci et al. [2006] contend that achieving a wide field-of-view (FOV) is the major optical design challenge in AR NEDs.
    - td1:
        authors:
        - rshepherd
        - bpeele
        - bmacmurray
        - jbarreiros
        - oshapira
        - jspjut
        - dluebke
        title: Stretchable Transducers for Kinesthetic Interactions in Virtual Reality
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: Los Angeles
        month: July 30 - August 3
        year: 2017
        date: 2017-07-30
        paper: http://research.nvidia.com/sites/default/files/publications/peele_siggraph_etech17.pdf
        alternate: http://research.nvidia.com/publication/2017-06_Stretchable-Transducers-for
        thumbnail: etech17-orl-3.png
        banner: etech17-orl-2.png
        abstract: We provide two key demonstrations to highlight the use of fluidic elastomer actuators to provide haptic feedback. These demos allow users to progress through a series of brief experiences where the hand-held controller adjusts its form and behavior to match that of the virtual object used in each demo. The objects held in the demo include a goo gun, pistol and mallet.
    - td0:
        authors:
        - bpeele
        - bmacmurray
        - jbarreiros
        - rshepherd
        - oshapira
        - jspjut
        - dluebke
        title: Stretchable Transducers for Haptic Interactions in Virtual and Augmented Reality
        conference: GPU Technology Conference VR Village
        conf-short: GTC
        location: San Jose
        month: May 9 - 11
        year: 2017
        date: 2017-05-09
        thumbnail: etech17-orl.png
        banner: etech17-orl-2.png
---
name: Conference Talks and Courses
hugoid: 9
urlid: ct
pubs:
    - ct3:
        authors:
        - jspjut
        - bboudaoud
        title: "Foveated Displays: Toward Classification of the Emerging Field"
        conference: SIGGRAPH Talk
        conf-short: SIGGRAPH Talk
        location: Los Angeles
        month: July 28-31
        year: 2019
        date: 2019-07-28
        paper: https://doi.org/10.1145/3306307.3328145
        slides: https://drive.google.com/file/d/1-2-QUoRtV2AUTg3we-88sn8-D797ir8H/view?usp=sharing
        thumbnail: spjutfdt19.png
        banner: spjutfdt19.png
        abstract: There is not yet consensus in the field on what constitutes a ``foveated display''. We propose a compromise between the perspectives of rendering, imaging, physiology and vision science that defines a foveated display as a display designed to function in the context of user gaze. This definition enables us to describe 2 axes of foveation, gaze interaction and resolution distribution, which we then subdivide to provide useful categories for classification. We view this proposal as the start of a discussion among the community rather than a final taxonomy.
    - ct2:
        authors:
        - jspjut
        title: "The Augmented Frontier: Challenges for Near Eye Display Computing"
        conference: "[AR In Action](http://arinaction.org/)"
        conf-short: ARIA
        location: Boston
        month: January 16-17
        year: 2018
        date: 2018-01-16
        paper: http://josef.spjut.me/pubs/spjutARIA2018.pdf
        video: https://www.youtube.com/watch?v=sIqv-MJAwHo
        thumbnail: spjutaria18.png
        banner: nvresearch.png
        abstract: NVIDIA Research is developing solutions to upcoming difficulties for near eye displays for virtual and augmented reality. In this talk, I review some of the recent research projects from NVIDIA and our collaborators at various insitutions and how they contribute to our greater vision of near eye display computing replacing the existing ecosystem of mobile and desktop computing. 
        details: See also [The Virtual Fronteir](http://on-demand.gputechconf.com/siggraph/2017/video/sig1718-morgan-mcguire-virtual-frontier-computer-graphics.html) by Morgan McGuire from whom I borrowed many of the slides.
    - ct1:
        authors:
        - bpeele
        - bmacmurray
        - rshepherd
        - jbarreiros
        - oshapira
        - jspjut
        - dluebke
        title: Stretchable Transducers for Kinesthetic Interactions in Virtual Reality
        conference: SIGGRAPH Experience Presentations
        conf-short: SIGGRAPH Talk
        location: Los Angeles
        month: August 3
        year: 2017
        date: 2017-08-03
        paper: http://research.nvidia.com/sites/default/files/publications/peele_siggraph_etech17.pdf
        alternate: http://research.nvidia.com/publication/2017-06_Stretchable-Transducers-for
        thumbnail: etech17-orl-4.png
        banner: etech17-orl.png
        abstract: We provide two key demonstrations to highlight the use of fluidic elastomer actuators to provide haptic feedback. These demos allow users to progress through a series of brief experiences where the hand-held controller adjusts its form and behavior to match that of the virtual object used in each demo. The objects held in the demo include a goo gun, pistol and mallet.
    - ct0:
        authors:
        - jspjut
        - rpiersall
        - klau
        title: Build your own game controller
        conference: SIGGRAPH Studio
        conf-short: SIGGRAPH Studio
        location: Los Angeles
        month: August 10
        year: 2015
        date: 2015-08-10
        misc: (Studio Course)
        slides: http://josef.spjut.me/class/controllerCourseNotes.pdf
        webpage: http://josef.spjut.me/class/game-controller
        thumbnail: spjut15.jpg
        banner: spjut15.jpeg
---
name: Dissertation
hugoid: 10
urlid: dis
pubs:
    - d0:
        authors:
        - jspjut
        title: "Efficient Ray Tracing Architectures"
        conference: "University of Utah Dissertation"
        conf-short: Dissertation
        month: May
        year: 2015
        date: 2015-05-01
        paper: http://josef.spjut.me/pubs/thesis.pdf
        alternate: http://gradworks.umi.com/3727095.pdf
        alternate2: http://content.lib.utah.edu/cdm/ref/collection/etd3/id/3732
        thumbnail: spjut-dis.png
        banner: spjut-dis.png
        abstract: "This dissertation presents computer architecture designs that are efficient for ray tracing based rendering algorithms. The primary observation is that ray tracing maps better to independent thread issue hardware designs than it does to dependent thread and data designs used in most commercial architectures. While the independent thread issue causes extra overhead in the fetch and issue parts of the pipeline, the number of computation resources required can be reduced through the sharing of less frequently used execution units. Furthermore, since all the threads run a single program on multiple data (SPMD), thread processors can share instruction and data caches. Ray tracing needs read-only access to the scene data during each frame, so caches can be optimized for reading, and traditional cache coherence protocols are unnecessary for maintaining coherent memory access. The resultant image exists as a write only frame buffer, allowing memory writes to avoid the cache entirely, preventing cache pollution and increasing the performance of smaller caches.
        Commercial real-time rendering systems lean heavily on high-performance graphics processing units (GPU) that use the rasterization and z-buffer algorithms for rendering. A single pass of rasterization throws out much of the global scene information by streaming the surface data that a ray tracer keeps resident in memory. As a result, ray tracing is more naturally able to support rendering effects involving global information, such as shadows, reflections, refractions and camera lens effects. Rasterization has a time complexity of approximately O(Nlog(P)) where N is the number of primitive polygons and P is the number of pixels in the image. Ray tracing, in contrast, has a time complexity of O(Plog(N)) making ray tracing scale better to large scenes with many primitive polygons, allowing for increased surface detail. Finally, once the number of pixels reaches its limit, ray tracing should exceed the performance of rasterization by allowing the number of objects to increase with less of a penalty on performance."
---
name: Patents
hugoid: 12
urlid: pat
pubs:
    - pat5:
        authors:
            - pknowles
            - bboudaoud
            - jspjut
            - mmcguire
            - kbinaee
            - joohwankim
            - hvutukuru
        title: "Hardware acceleration and event decisions for late latch and warp in interactive computer products"
        year: 2021
        date: 2021-12-31
        misc: pending
        paper: https://patents.google.com/patent/US20210106912A1/en
        abstract: "The disclosure provides features or schemes that improve a user's experience with an interactive computer product by reducing latency through late latching and late warping. The late warping can be applied by imaging hardware based on late latch inputs and is applicable for both local and cloud computing environments. In one aspect, the disclosure provides a method of operating an imaging system employing late latching and late warping. In one example the method of operating an imaging system includes: (1) rendering a rendered image based on a user input from an input device and scene data from an application engine, (2) obtaining a late latch input from the input device, (3) rendering, employing imaging hardware, a warped image by late warping at least a portion of the rendered image based on the late latch input, and (4) updating state information in the application engine with late latch and warp information."
    - pat4:
        authors:
            - joohwankim
            - jspjut
            - ifrosio
            - ogallo
            - eprashnani
        title: "Gaze determination using one or more neural networks"
        year: 2021
        date: 2021-12-31
        misc: Pending
        paper: https://patents.google.com/patent/US20210132688A1/en
        abstract: "Apparatuses, systems, and techniques are presented to modify media content using inferred attention. In at least one embodiment, a network is trained to predict a gaze of one or more users on one or more image features based, at least in part, on one or more prior gazes of the one or more users, wherein the prediction is to be used to modify at least one of the one or more image features."
    - pat3:
        authors:
            - pandersson
            - takeninemoller
            - jnilsson
            - msalvi
            - jspjut
        title: "Reconstruction for temporally dense ray trace rendering"
        year: 2021
        date: 2021-12-31
        misc: Pending
        paper: https://patents.google.com/patent/US20200312010A1/en
        abstract: "A method dynamically selects one of a first sampling order and a second sampling order for a ray trace of pixels in a tile where the selection is based on a motion vector for the tile. The sampling order may be a bowtie pattern or an hourglass pattern. Subframes generated based on the sampling order are communicated over a bus along with motion vectors for tiles of the subframes."
    - pat2:
        authors:
            - hgruen
            - amarrs
            - jspjut
            - rsathe
            - mmcguire
        title: "Adding greater realism to a computer-generated image by smoothing jagged edges within the image in an efficient manner"
        year: 2021
        date: 2021-12-31
        misc: Pending
        paper: https://patents.google.com/patent/US20190318455A1/en
        abstract: "During the rendering of an image, specific pixels in the image are identified where antialiasing would be helpful. Antialiasing is then performed on these identified pixels, where antialiasing is a technique used to add greater realism to a digital image by smoothing jagged edges. This reduces a cost of performing antialiasing by reducing a number of pixels within an image on which antialiasing is performed."
    - pat1:
        authors:
            - amarrs
            - jspjut
            - hgruen
            - mmcguire
            - rsathe
        title: "Adding greater realism to a computer-generated image by smoothing jagged edges"
        year: 2021
        date: 2021-12-31
        misc: Pending
        paper: https://patents.google.com/patent/US20190318454A1/en
        abstract: "During the rendering of an image, specific pixels in the image are identified where antialiasing would be helpful. Antialiasing is then performed on these identified pixels, where anti-aliasing is a technique used to add greater realism to a digital image by smoothing jagged edges. This reduces a cost of performing antialiasing by reducing a number of pixels within an image on which antialiasing is performed."
    - pat0:
        authors:
            - tgreer
            - jspjut
            - dluebke
        title: "Retina space display stabilization and a foveated display for augmented reality"
        year: 2021
        date: 2021-03-16
        misc: Granted
        paper: https://patents.google.com/patent/US20190302883A1/en
        abstract: "Perceived clarity of an image presented by a display can be improved using an image stabilization technique to stabilize the image relative to a user's retina. During an illumination period, stabilization actuators are controlled to move a display panel or adjust optical components in the path of light associated with the image to shift the location of the image on the user's retina in response to head or eye movement detected by the system. In some embodiments, a display is configured to illuminate an image, and at least one stabilization actuator is configured to stabilize the image in a retina space associated with a user. Changes in the retina space can be detected by one or more sensors configured to detect a head position of the user and/or an orientation of the user's retina. The image is stabilized in retina space using the stabilization actuators."
---
name: Technical Reports
hugoid: 4
urlid: tr
pubs:
    - tr11:
        authors:
            - eprashnani
            - ogallo
            - joohwankim
            - jspjut
            - psen
            - ifrosio
        title: "Noise-Aware Saliency Prediction for Videos with Incomplete Gaze Data"
        conference: Tech Report
        conf-short: Tech Report
        month: April 16
        year: 2021
        date: 2021-04-16
        paper: https://arxiv.org/pdf/2104.08038
        alternate: https://arxiv.org/abs/2104.08038
        abstract: "Deep-learning-based algorithms have led to impressive results in visual-saliency prediction, but the impact of noise in training gaze data has been largely overlooked. This issue is especially relevant for videos, where the gaze data tends to be incomplete, and thus noisier, compared to images. Therefore, we propose a noise-aware training (NAT) paradigm for visual-saliency prediction that quantifies the uncertainty arising from gaze data incompleteness and inaccuracy, and accounts for it in training. We demonstrate the advantage of NAT independently of the adopted model architecture, loss function, or training dataset. Given its robustness to the noise in incomplete training datasets, NAT ushers in the possibility of designing gaze datasets with fewer human subjects. We also introduce the first dataset that offers a video-game context for video-saliency research, with rich temporal semantics, and multiple gaze attractors per frame."
        thumbnail: prashnani21.png
        banner: prashnani21.png
    - tr10:
        authors:
            - zmajercik
            - amarrs
            - jspjut
            - mmcguire
        title: "Scaling Probe-Based Real-Time Dynamic Global Illumination for Production"
        conference: Tech Report
        conf-short: Tech Report
        month: Sep 22
        year: 2020
        date: 2020-09-22
        paper: https://arxiv.org/pdf/2009.10796
        alternate: https://arxiv.org/abs/2009.10796
        abstract: "We contribute several practical extensions to the probe based irradiance-field-with-visibility representation to improve image quality, constant and asymptotic performance, memory efficiency, and artist control. We developed these extensions in the process of incorporating the previous work into the global illumination solutions of the NVIDIA RTXGI SDK, the Unity and Unreal Engine 4 game engines, and proprietary engines for several commercial games. These extensions include: a single, intuitive tuning parameter (the 'self-shadow' bias); heuristics to speed transitions in the global illumination; reuse of irradiance data as prefiltered radiance for recursive glossy reflection; a probe state machine to prune work that will not affect the final image; and multiresolution cascaded volumes for large worlds."
        thumbnail: majercik20.png
        banner: majercik20.png
    - tr9:
        authors:
            - jspjut
            - bboudaoud
            - jonghyunkim
            - tgreer
            - ralbert
            - mstengel
            - kaksit
            - dluebke
        title: "Toward Standardized Classification of Foveated Displays"
        conference: Tech Report
        conf-short: Tech Report
        month: May 3
        year: 2019
        date: 2019-05-03
        paper: https://arxiv.org/pdf/1905.06229
        alternate: https://arxiv.org/abs/1905.06229
        abstract: "Emergent in the field of head mounted display design is a desire to leverage the limitations of the human visual system to reduce the computation, communication, and display workload in power and form-factor constrained systems. Fundamental to this reduced workload is the ability to match display resolution to the acuity of the human visual system, along with a resulting need to follow the gaze of the eye as it moves, a process referred to as foveation. A display that moves its content along with the eye may be called a Foveated Display, though this term is also commonly used to describe displays with non-uniform resolution that attempt to mimic human visual acuity. We therefore recommend a definition for the term Foveated Display that accepts both of these interpretations. Furthermore, we include a simplified model for human visual Acuity Distribution Functions (ADFs) at various levels of visual acuity, across wide fields of view and propose comparison of this ADF with the Resolution Distribution Function of a foveated display for evaluation of its resolution at a particular gaze direction. We also provide a taxonomy to allow the field to meaningfully compare and contrast various aspects of foveated displays in a display and optical technology-agnostic manner."
        thumbnail: spjutfdtr19.png
        banner: spjutfdtr19.png
    - tr8:
        authors:
            - kshkurko
            - tgrant
            - elb
            - dkopta
            - jspjut
            - evasiou
            - imallett
            - cyuksel
        title: "SimTrax: Simulation Infrastructure for Exploring Thousands of Cores"
        conference: Tech Report
        conf-short: Tech Report
        month: March 29
        year: 2018
        date: 2018-03-29
        paper: http://josef.spjut.me/pubs/shkurko18_tr.pdf
        abstract: "SimTRaX is a simulation infrastructure for simultaneous exploration of highly parallel accelerator architectures and how applications map to them. The infrastructure targets both cycle-accurate and functional simulation of architectures with thousands of simple cores that may share expensive computation and memory resources. A modified LLVM backend used to compile C++ programs for the simulated architecture allows the user to create custom instructions that access proposed special-purpose hardware and to debug and profile the applications being executed. The simulator models a full memory hierarchy including registers, local scratchpad RAM, shared caches, external memory channels, and DRAM main memory, leveraging the USIMM DRAM simulator to provide accurate dynamic latencies and power usage. SimTRaX provides a powerful and flexible infrastructure for exploring a class of extremely parallel architectures for parallel applications that are not easily simulated using existing simulators."
        thumbnail: shkurko18.png
        banner: shkurko18.png
    - tr7:
        authors:
        - clarson
        - jspjut
        - rknepper
        - rshepherd
        title: "OrbTouch: Recognizing Human Touch in Deformable Interfaces with Deep Neural Networks"
        conference: "Tech Report, arXiv:1706.02542"
        conf-short: Tech Report
        month: June
        year: 2017
        date: 2017-06-08
        paper: https://arxiv.org/abs/1706.02542
        thumbnail: clarson17.png
        banner: clarson17.png
    - tr6:
        authors:
        - jsung
        - skrupa
        - afishberg
        - jspjut
        title: An Approach to Data Prefetching Using 2-Dimensional Selection Criteria
        conference: "Tech Report, arXiv:1505.03899"
        conf-short: Tech Report
        month: May
        year: 2015
        date: 2015-05-01
        paper: http://arxiv.org/abs/1505.03899
        thumbnail: sung15.png
    - tr5:
        authors:
        - dhpark
        - abagaria
        - fhannan
        - estorm
        - jspjut
        title: "Sphynx: A Shared Instruction Cache Exporatory Study"
        conference: "Tech Report, arXiv:1412.1140"
        conf-short: Tech Report
        month: December 3 
        year: 2014
        date: 2014-12-03
        paper: http://arxiv.org/abs/1412.1140
        thumbnail: park14.png
        banner: park14.png
    - tr4:
        authors:
        - estorm
        - jspjut
        title: "A Time-to-Recache Case Study"
        conference: "Tech Report"
        month: March
        year: 2014
        date: 2014-03-01
        paper: http://josef.spjut.me/pubs/stormttr14.pdf
        thumbnail: storm14.png
    - tr3:
        authors:
        - acarter
        - mkorbel
        - pning
        - jspjut
        title: "Qualitative Cache Performance Analysis"
        conference: "Tech Report"
        month: September
        year: 2013
        date: 2013-09-01
        paper: http://josef.spjut.me/pubs/carterttr13.pdf
        thumbnail: carter13.png
    - tr2:
        authors:
        - jspjut
        - spugsley
        title: "Time to Recache: Measuring Memory Miss Behavior"
        conference: "Tech Report"
        month: September
        year: 2011
        date: 2011-09-01
        paper: http://josef.spjut.me/pubs/ttr11.pdf
        thumbnail: ttr11.png
    - tr1:
        authors:
        - dkopta
        - aek
        - tize
        - jspjut
        - elb
        - ald
        title: Fast, Effective BVH Updates for Dynamic Ray-Traced Scenes Using Tree Rotations
        conference: Tech Report, UUCS 11-002, University of Utah
        conf-short: Tech Report
        month: July 
        year: 2011
        date: 2011-07-01
        paper: https://pdfs.semanticscholar.org/c352/f679482dcea78e1abe0913b8e12d1c52ae5b.pdf
        thumbnail: kopta12.png
        banner: kopta12.png
---
name: Refereed Posters
hugoid: 11
urlid: pos
pubs:
    - p5:
        authors:
        - jspjut
        - bboudaoud
        - kbinaee
        - zmajercik
        - mmcguire
        - joohwankim
        title: "FirstPersonScience: Quantifying Psychophysics for First Person Shooter Tasks"
        conference: UCI Esports Conference
        conf-short: ESC
        location: Irvine
        month: October 10-12
        year: 2019
        date: 2019-10-10
        paper: http://josef.spjut.me/pubs/spjut19esc_paper.pdf
        alternate: https://uciesportsconference2019.sched.com/event/UQdr/posters-reception-heavy-hors-doeuvres-gallery
        thumbnail: spjut19-esc.png
        banner: spjut19-esc.png
        abstract: "In the emerging field of esports research, there is an increasing demand for quantitative results that can be used by players, coaches and analysts to make decisions and present meaningful commentary for spectators. We present FirstPersonScience, a software application intended to fill this need in the esports community by allowing scientists to design carefully controlled experiments and capture accurate results in the First Person Shooter esports genre. An experiment designer can control a variety of parameters including target motion, weapon configuration, 3D scene, frame rate, and latency. Furthermore, we validate this application through careful end-to-end latency analysis and provide a case study showing how it can be used to demonstrate the training effect of one user given repeated task performance."
    - p4:
        authors:
        - joohwankim
        - jspjut
        - mmcguire
        - zmajercik
        - bboudaoud
        - ralbert
        - dluebke
        title: "Esports Arms Race: Latency and Refresh Rate for Competitive Gaming Tasks"
        conference: Vision Science Society
        conf-short: VSS
        location: St. Pete Beach
        month: May 17-22
        year: 2019
        date: 2019-05-17
        paper: https://www.visionsciences.org/programs/VSS_2019_Abstracts.pdf
        thumbnail: kim19-vss.png
        banner: kim19-vss.png
        abstract: "In the world of esports (competitive video games), hardware and software configurations are optimized for winning. In many games this means minimizing latency ('I see you before you see me') and maximizing refresh rate ('I see your move more accurately'). Most esports athletes and competitive players ensure this by using high-end hardware (computers, monitors, and GPUs) while turning off superfluous in-game graphics features. By doing so, one can demonstrate the competitive benefit of modern display technologies. We conducted two user studies that compare esports performance using common display settings. We conclude that 240 hz, today's highest-speed display technology, provides a competitive advantage."
    - p3:
        authors:
        - mjalal
        - jspjut
        - bboudaoud
        - mbetke
        title: Large-scale Synthetic Domain Randomized 6DoF Object Pose Estimation Dataset
        conference: New England Computer Vision Workshop
        conf-short: NECV
        location: Boston
        month: November 26
        year: 2018
        date: 2018-11-26
        paper: http://josef.spjut.me/pubs/jalal18_poster.pdf
        thumbnail: jalal18.png
        banner: jalal18.png
    - p2:
        authors:
        - dkopta
        - jspjut
        - elb
        title: Grid-Based Ray Tracing for a Parallel Computing Architecture
        conference: High Performance Graphics (HPG'09)
        conf-short: HPG
        location: New Orleans
        month: August 1-3
        year: 2009
        date: 2009-08-01
        paper: http://josef.spjut.me/pubs/HPG09_poster.pdf
        thumbnail: koptaposter09.png
    - p1:
        authors:
        - dkopta
        - jspjut
        - elb 
        - sparker
        title: Comparing Incoherent Ray Performance of TRaX vs. Manta
        conference: IEEE Symposium on Interactive Ray Tracing (RT08)
        conf-short: RT
        month: August 9-10
        year: 2008
        date: 2008-08-09
        paper: http://josef.spjut.me/pubs/kopta_rt08.pdf
        alternate: http://josef.spjut.me/pubs/koptaGradPoster2009.pdf
        thumbnail: koptaposter08.png
        abstract: TRaX (Threaded Ray eXecution) is a highly parallel multi-threaded, multi-core processor architecture designed for real-time ray tracing. One motivation behind TRaX is to accelerate single-ray performance instead of relying on ray-packets in SIMD mode to boost throughput, which can fail as packets become incoherent. To evaluate the effectiveness of this approach we implement a path tracer on the TRaX simulator and measure performance as the secondary rays become less coherent. We are able to show that TRaX exhibits only minor slowdown on highly incoherent rays compared to a well-optimized SIMD-packet based path tracer which suffers significant slowdown as rays become incoherent.
---
name: Unpublished
hugoid: -1
urlid: unpub
pubs:
    - up4:
        authors:
        - joohwankim
        - bboudaoud
        - mmcguire
        title: esports research
        year: 2020
        date: 2020-12-31
    - tr10:
        authors:
        - nkalavakonda
        - jspjut
        - bboudaoud
        title: TrackNN
        year: 2018
        date: 2018-11-28
    - up3:
        authors:
        - dluebke
        - jtw
        - tgreer
        - mmcguire
        - balfieri
        title: NVIDIA ongoing
        year: 2018
        date: 2018-08-31
    - up2:
        authors:
        - jspjut
        - taila
        - tkarras
        - slaine
        - dluebke
        title: NVIDIA 2015
        year: 2015
        date: 2015-05-30
    - up1:
        authors:
        - mparker
        title: NVIDIA 2013
        year: 2013
        date: 2013-09-01
    - up0:
        authors:
        - jspjut
        - fvahid
        - dsheldon
        - ssirowy
        - rlysecky
        title: UCR
        year: 2006
        date: 2006-06-20
...






