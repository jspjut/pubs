---
name: Refereed Publications
hugoid: 7
urlid: ref
pubs: 
    - c31:
        authors:
            - sstokey
            - zchen
            - cmettler
            - dtang
            - bboudaoud
            - joohwankim
            - jspjut
            - mclaypool
        title: "The Effects of Network Latency on the Peeker's Advantage in First-person Shooter Games"
        conference: IEEE Computer Graphics and Applications
        conf-short: IEEE CG&A
        month: May 21
        year: 2024
        date: 2024-05-21
        paper: https://web.cs.wpi.edu/~claypool/papers/peeker-fdg-24/paper.pdf
        alternate: https://dl.acm.org/doi/10.1145/3649921.3650002
        abstract: "In first-person shooter (FPS) games, the peeker's advantage is the edge the moving peeker gets when battling a stationary defender at a corner due to network latency. However, confirmation of (the size of) this advantage based on network latency and the distance from the corner has not been studied. This paper assesses the peeker's advantage via two user studies both using an open-source FPS game extended to support two-player networking and a custom map. Users play as both peeker and defender with 3 different corner distances and 3 different network latencies. Analysis of hits, wins, and time-to-damage shows that the advantage for the peeker is impacted more by the defender's latency than the peeker's latency and is lowest when the peeker is nearest the corner. The user study with a tournament setting had quicker and more competitive matches resulting in more combat encounters and closer games than did the traditional user study."
        thumbnail: tokey24peek.png
        banner: tokey24peek.png
    - c30:
        authors:
            - bwatson
            - jspjut
            - joohwankim
            - blee
            - myoo
            - pshirley
            - rraymond
        title: "Is Less More? Rendering for Esports"
        conference: IEEE Computer Graphics and Applications
        conf-short: IEEE CG&A
        month: March 27
        year: 2024
        date: 2024-03-27
        paper: https://ieeexplore.ieee.org/abstract/document/10478358
        alternate: https://research.nvidia.com/index.php/publication/2024-03_less-more-rendering-esports
        abstract: "Computer graphics research has long prioritized image quality over frame rate. Yet demand for an alternative is growing, with many esports players turning off visual effects to improve frame rates. Is it time for graphics researchers to reconsider their goals? A workshop at the 2023 SIGGRAPH Conference explored this question. Three researchers made provocative presentations, each of which were then discussed by dozens of research and industry attendees. We summarize those presentations and discussions here, concluding with potential research questions, and future plans for esports at SIGGRAPH."
        thumbnail: watson24.png
        banner: watson24.png
    - c29:
        authors:
            - bboudaoud
            - jspjut
            - joohwankim
        title: "Mouse Sensitivity in First-person Targeting Tasks"
        conference: IEEE Transactions on Games
        conf-short: IEEE Games
        month: July 17
        year: 2023
        date: 2023-07-17
        paper: https://ieeexplore.ieee.org/document/10184504
        alternate: 
        abstract: "Mouse sensitivity in first-person targeting tasks is a highly debated issue. Recommendations within a single game can vary by a factor of 10x or more and are an active topic of experimentation in both competitive and recreational esports communities. Inspired by work in pointer-based gain optimization and extending our previous results from the first user study focused on mouse sensitivity in first-person targeting tasks, we describe a range of optimal mouse sensitivity wherein players perform statistically significantly better in task completion time and throughput. For tasks involving first-person view control, mouse sensitivity is best described using the ratio between an in-game rotation of the view and corresponding physical displacement of the mouse. We discuss how this displacement-to-rotation sensitivity is incompatible with the Control-Display (CD) gain reported in traditional pointer-based gain studies as well as other rotational gains reported in head-controlled interface studies. We provide additional details regarding impacts of mouse dots per inch (DPI), on reported sensitivity, the distribution of spatial difficulty in our experiment, our submovement parsing algorithm, and relationships between measured parameters, further demonstrating optimal sensitivity arising from a speed-precision trade-off. We conclude our work by updating and improving our suggestions for mouse sensitivity selection and refining directions for future work."
        thumbnail: boudaoud22.png
        banner: boudaoud22.png
    - c28:
        authors:
            - joohwankim
            - amadhusudan
            - bwatson
            - bboudaoud
            - rtarrazo
            - jspjut
        title: "Display Size and Targeting Performance: Small Hurts, Large May Help"
        conference: SIGGRAPH Asia
        conf-short: SIGGRAPH Asia
        month: November 22
        year: 2022
        date: 2022-12-06
        paper: https://dl.acm.org/doi/10.1145/3550469.3555396
        alternate: https://research.nvidia.com/index.php/publication/2022-12_display-size-and-targeting-performance-small-hurts-large-may-help
        abstract: "Which display size helps gamers win? Recommendations from the research and PC gaming communities are contradictory. We find that as display size grows, targeting performance improves. When size increases from 13\" to 26\", targeting time drops by over 3%. Further size increases from 26\" through 39\", 52\" and 65\", bring more modest improvements, with targeting time dropping a further 1%. While such improvements may not be meaningful for novice gamers, they are extremely important to skilled and competitive players. To produce these results, 30 gamers participated in a targeting task as we varied display size by placing a display at varying distances. We held field of view constant by varying viewport size, and resolution constant by rendering to a fixed-size off-screen buffer. This paper offers further experimental detail, and examines likely explanations for the effects of display size."
        thumbnail: kim22.png
        banner: kim22.png
    - c27:
        authors:
            - bboudaoud
            - jspjut
            - joohwankim
            - amadhusudan
            - bwatson
        title: "Esports and expertise: what competitive gaming can teach us about mastery"
        conference: ACM Interactions
        conf-short: Interactions
        month: November-December
        year: 2022
        date: 2022-11-03
        paper: https://dl.acm.org/doi/10.1145/3567954
        alternate: https://research.nvidia.com/index.php/publication/2022-11_esports-and-expertise-what-competitive-gaming-can-teach-us-about-mastery
        abstract: "Historically, much research and development in human computer interaction has focused on atomic and generalizable tasks, where task completion time indicates productivity. However, the emergence of competitive games and esports reminds us of an alternative perspective on human performance in HCI: mastery of higher-level, holistic practices. Just as a world-renowned artist is rarely evaluated for their individual brush strokes, so skilled competitive gamers rarely succeed solely by completing individual mouse movements or keystrokes as quickly as possible. Instead, they optimize more task-specific skills, adeptly performing challenges deep in the learning curve for their game of choice."
        thumbnail: boudaoud22b.png
        banner: boudaoud22b.png
    - c26:
        authors:
            - bboudaoud
            - jspjut
            - joohwankim
        title: "Mouse Sensitivity in First-person Targeting Tasks"
        conference: IEEE Conference on Games
        conf-short: IEEE CoG
        month: August 21
        year: 2022
        date: 2022-08-21
        paper: https://ieeexplore.ieee.org/document/9893626
        alternate: https://research.nvidia.com/index.php/publication/2022-08_mouse-sensitivity-first-person-targeting-tasks
        abstract: "Despite billions of hours of play and copious discussion online, mouse sensitivity recommendations for first-person targeting tasks vary by a factor of 10x or more and remain an active topic of debate in both competitive and recreational gaming communities.Inspired by previous academic literature in pointer-based gain optimization, we conduct the first user study of mouse sensitivity in first person targeting tasks, reporting a statistically significant range of optimal values in both task completion time and throughput. Due to inherent incompatibility (i.e., lack of convert-ability) between sensitivity metrics adopted for prior pointer-based gain literature and those describing first-person targeting, we provide the first analytically demonstrated, statistically significant optimal sensitivity range useful for first-person camera controls. Furthermore, we demonstrate that this optimal sensitivity range arises (at least in part) from a speed-precision trade-off impacted by spatial task difficulty, similar to results reported in pointer-based sensitivity literature previously."
        thumbnail: boudaoud22.png
        banner: boudaoud22.png
    - c25:
        authors:
            - skriglstein
            - amartin
            - jspjut
            - ndamen
            - sturkay
            - adrachen
        title: "Esports Meets Human-Computer Interaction"
        conference: ACM Interactions
        conf-short: Interactions
        month: May 2
        year: 2022
        date: 2022-05-02
        paper: https://dl.acm.org/doi/10.1145/3524855
        alternate: 
        abstract: "Using technology in esports can address historical disparities such as gender, age, and ableism in professional play. To advance the field, it is important to focus on interdisciplinary esports research networks and communities. Topics relevant for future HCI/esports research include competitive physical sports versus esports, spectatorship, and inclusion."
        thumbnail: kriglstein22.png
        banner: kriglstein22.png
    - c24:
        authors:
            - eprashnani
            - ogallo
            - joohwankim
            - jspjut
            - psen
            - ifrosio
        title: "Noise-Aware Saliency Prediction for Videos with Incomplete Gaze Data"
        conference: The British Machine Vision Conference
        conf-short: BMVC
        month: November 22
        year: 2021
        date: 2021-11-22
        paper: https://arxiv.org/pdf/2104.08038
        alternate: https://arxiv.org/abs/2104.08038
        abstract: "We tackle the problem of predicting saliency maps for videos of dynamic scenes. We note that the accuracy of the maps reconstructed from the gaze data of a fixed number of observers varies with the frame, as it depends on the content of the scene. This issue is particularly pressing when a limited number of observers are available. In such cases, directly minimizing the discrepancy between the predicted and measured saliency maps, as traditional deep-learning methods do, results in overfitting to the noisy data. We propose a noise-aware training (NAT) paradigm that quantifies and accounts for the uncertainty arising from frame-specific gaze data inaccuracy. We show that NAT is especially advantageous when limited training data is available, with experiments across different models, loss functions, and datasets. We also introduce a video game-based saliency dataset, with rich temporal semantics, and multiple gaze attractors per frame. The dataset and source code are available at https://github.com/NVlabs/NAT-saliency"
        thumbnail: prashnani21.png
        banner: prashnani21.png
    - c23:
        authors:
            - jspjut
            - bboudaoud
            - joohwankim
        title: A Case Study of First Person Aiming at Low Latency for Esports
        conference: Esports and High-Performance Human-Computer Interaction Workshop
        conf-short: EHPHCI
        month: May 8
        year: 2021
        date: 2021-05-08
        paper: https://osf.io/nu9p3/
        alternate: https://research.nvidia.com/publication/2021-05_A-Case-Study
        abstract: "Lower computer system input-to-output latency substantially re-duces many task completion times. In fact, literature shows that reduction in targeting task completion time from decreased latency often exceeds the decrease in latency alone. However, for aiming in first person shooter (FPS) games, some prior work has demonstrated diminishing returns below 40 ms of local input-to-output computer system latency. In this paper, we review this prior art and provide an additional case study with data demonstrating the importance of local system latency improvement, even at latency values below 20 ms. Though other factors may determine victory in a particular esports challenge, ensuring balanced local computer latency among competitors is essential to fair competition."
        thumbnail: spjut21ehphci.png
        banner: spjut21ehphci.png
    - c22:
        authors:
            - zmajercik
            - amarrs
            - jspjut
            - mmcguire
        title: "Scaling Probe-Based Real-Time Dynamic Global Illumination for Production"
        conference: The Journal of Computer Graphics Techniques
        conf-short: JCGT
        month: May 3
        year: 2021
        date: 2021-05-03
        paper: http://jcgt.org/published/0010/02/01/
        abstract: "We contribute several practical extensions to the probe-based irradiance-field-with-visibility representation [Majercik et al. 2019] [McGuire et al. 2017] to improve image quality, constant and asymptotic performance, memory efficiency, and artist control. We developed these extensions in the process of incorporating the previous work into the global illumination solutions of the NVIDIA RTXGI SDK, the Unity and Unreal Engine 4 game engines, and proprietary engines for several commercial games. These extensions include: an intuitive tuning parameter (the self-shadow bias); heuristics to speed transitions in the global illumination; reuse of irradiance data as prefiltered radiance for recursive glossy reflection; a probe state machine to prune work that will not affect the final image; and multiresolution cascaded volumes for large worlds."
        thumbnail: majercik21.png
        banner: majercik21.png
    - c21:
        authors:
            - joohwankim
            - pknowles
            - jspjut
            - bboudaoud
            - mmcguire
        title: "Post-Render Warp with Late Input Sampling Improves Aiming Under High Latency Conditions"
        conference: Proceedings of the ACM on Computer Graphics and Interactive Techniques
        conf-short: PACM CGIT
        month: July 13-16
        year: 2020
        date: 2020-07-13
        paper: http://josef.spjut.me/pubs/kim_hpg2020_author.pdf
        alternate: https://research.nvidia.com/publication/2020-07_Post-Render-Warp-with
        alternate2: https://doi.org/10.1145/3406187
        abstract: "End-to-end latency in remote-rendering systems can reduce user task performance. This notably includes aiming tasks on game streaming services, which are presently below the standards of competitive first-person desktop gaming. We evaluate the latency-induced penalty on task completion time in a controlled environment and show that it can be significantly mitigated by adopting and modifying image and simulation-warping techniques from virtual reality, eliminating up to 80% of the penalty from 80 ms of added latency. This has potential to enable remote rendering for esports and increase the effectiveness of remote-rendered content creation and robotic teleoperation. We provide full experimental methodology, analysis, implementation details, and source code."
        thumbnail: kimhpg20.png
        banner: kimhpg20.png
    - c20:
        authors:
            - jspjut
            - bboudaoud
            - jonghyunkim
            - tgreer
            - ralbert
            - mstengel
            - kaksit
            - dluebke
        title: "Toward Standardized Classification of Foveated Displays"
        conference: IEEE Transactions on Visualization and Computer Graphics
        conf-short: TVCG
        month: March 22
        year: 2020
        date: 2020-03-22
        paper: https://ieeexplore.ieee.org/document/8999630
        alternate: https://arxiv.org/abs/1905.06229
        alternate2: https://doi.org/10.1109/TVCG.2020.2973053
        abstract: "Emergent in the field of head mounted display design is a desire to leverage the limitations of the human visual system to reduce the computation, communication, and display workload in power and form-factor constrained systems. Fundamental to this reduced workload is the ability to match display resolution to the acuity of the human visual system, along with a resulting need to follow the gaze of the eye as it moves, a process referred to as foveation. A display that moves its content along with the eye may be called a Foveated Display, though this term is also commonly used to describe displays with non-uniform resolution that attempt to mimic human visual acuity. We therefore recommend a definition for the term Foveated Display that accepts both of these interpretations. Furthermore, we include a simplified model for human visual Acuity Distribution Functions (ADFs) at various levels of visual acuity, across wide fields of view and propose comparison of this ADF with the Resolution Distribution Function of a foveated display for evaluation of its resolution at a particular gaze direction. We also provide a taxonomy to allow the field to meaningfully compare and contrast various aspects of foveated displays in a display and optical technology-agnostic manner."
        thumbnail: spjutvr20.png
        banner: spjutvr20.png
    - c19:
        authors:
            - jspjut
            - bboudaoud
            - kbinaee
            - jonghyunkim
            - zmajercik
            - mmcguire
            - dluebke
            - joohwankim
        title: "Latency of 30 ms Benefits First Person Targeting Tasks More Than Refresh Rate Above 60 Hz"
        conference: SIGGRAPH Asia Technical Briefs
        conf-short: SA'19 Technical Briefs
        month: November 17-20
        year: 2019
        date: 2019-11-17
        paper: https://research.nvidia.com/publication/2019-11_Latency-of-30
        alternate: https://dl.acm.org/citation.cfm?id=3365170
        alternate2: https://research.nvidia.com/sites/default/files/pubs/2019-11_Latency-of-30/FPS_Tasks_sa2019_AuthorVersion.pdf
        abstract: "In competitive sports, human performance makes the difference between who wins and loses. In some competitive video games (esports), response time is an essential factor of human performance. When the athlete's equipment (computer, input and output device) responds with lower latency, it provides a measurable advantage. In this study, we isolate latency and refresh rate by artificially increasing latency when operating at high refresh rates. Eight skilled esports athletes then perform gaming-inspired first person targeting tasks under varying conditions of refresh rate and latency, completing the tasks as quickly as possible. We show that reduced latency has a clear benefit in task completion time while increased refresh rate has relatively minor effects on performance when the inherent latency reduction present at high refresh rates is removed. Additionally, for certain tracking tasks, there is a small, but marginally significant effect from high refresh rates alone."
        thumbnail: spjut19-sa.png
        banner: spjut19-sa.png
    - c18:
        authors:
            - clarson
            - jspjut
            - rknepper
            - rshepherd
        title: "A deformable interface for human touch recognition using stretchable carbon nanotube dielectric elastomer sensors and deep neural networks"
        conference: Soft Robotics
        conf-short: SoRo
        month: October 4
        year: 2019
        date: 2019-10-04
        paper: https://www.liebertpub.com/doi/pdf/10.1089/soro.2018.0086
        alternate: https://www.liebertpub.com/doi/full/10.1089/soro.2018.0086
        abstract: "This article presents a machine learning approach to map outputs from an embedded array of sensors distributed throughout a deformable body to continuous and discrete virtual states, and its application to interpret human touch in soft interfaces. We integrate stretchable capacitors into a rubber membrane, and use a passive addressing scheme to probe sensor arrays in real time. To process the signals from this array, we feed capacitor measurements into convolutional neural networks that classify and localize touch events on the interface. We implement this concept with a device called OrbTouch. To modularize the system, we use a supervised learning approach wherein a user defines a set of touch inputs and trains the interface by giving it examples; we demonstrate this by using OrbTouch to play the popular game Tetris. Our regression model localizes touches with mean test error of 0.09 mm, whereas our classifier recognizes five gestures with a mean test error of 1.2%. In a separate demonstration, we show that OrbTouch can discriminate between 10 different users with a mean test error of 2.4%. At test time, we feed the outputs of these models into a debouncing algorithm to provide a nearly error-free experience."
        thumbnail: clarson19.png
        banner: clarson19.png
    - c16:
        authors:
            - jonghyunkim
            - youngmojeong
            - mstengel
            - kaksit
            - ralbert
            - bboudaoud
            - tgreer
            - joohwankim
            - wlopes
            - zmajercik
            - pshirley
            - jspjut
            - mmcguire
            - dluebke
        title: "Foveated AR: Dynamically-Foveated Augmented Reality Display"
        conference: ACM SIGGRAPH Proceedings
        conf-short: SIGGRAPH
        location: Los Angeles
        month: July
        year: 2019
        date: 2019-07-28
        paper: https://research.nvidia.com/sites/default/files/pubs/2019-07_Foveated-AR%3A-Dynamically-Foveated//Foveated_AR___v2%20%2815%29.pdf
        alternate: https://research.nvidia.com/publication/2019-07_Foveated-AR%3A-Dynamically-Foveated
        abstract: "We present a near-eye augmented reality display with resolution and focal depth dynamically driven by gaze tracking. The display combines a traveling microdisplay relayed off a concave half-mirror magnifier for the high-resolution foveal region, with a wide field-of-view peripheral display using a projector-based Maxwellian-view display whose nodal point is translated to follow the viewer's pupil during eye movements using a traveling holographic optical element.  The same optics relay an image of the eye to an infrared camera used for gaze tracking, which in turn drives the foveal display location and peripheral nodal point. Our display supports accommodation cues by varying the focal depth of the microdisplay in the foveal region, and by rendering simulated defocus on the 'always in focus' scanning laser projector used for peripheral display. The resulting family of displays significantly improves on the field-of-view, resolution, and form-factor tradeoff present in previous augmented reality designs.  We show prototypes supporting 30, 40 and 60 cpd foveal resolution at a net 85x78 degree field of view per eye."
        thumbnail: jkim19-foveatedar.png
        banner: jkim19-foveatedar.png
    - c17:
        authors:
            - pandersson
            - jnilsson
            - msalvi
            - jspjut
            - takeninemoller
        title: "Temporally Dense Ray Tracing"
        conference: High Performance Graphics
        conf-short: HPG
        location: Strasbourg
        month: July 8
        year: 2019
        date: 2019-07-08
        paper: https://research.nvidia.com/sites/default/files/pubs/2019-07_Temporally-Dense-Ray/temporally-dense-ray-tracing.pdf
        alternate: https://research.nvidia.com/publication/2019-07_Temporally-Dense-Ray
        abstract: "We present a technique for real-time ray tracing with the goal of reaching 240 frames per second or more. The core idea is to trade spatial resolution for faster temporal updates in such a way that the display and human visual system aid in integrating high-quality images. We use a combination of frameless and interleaved rendering concepts together with ideas from temporal antialiasing algorithms and novel building blocks---the major one being adaptive selection of pixel orderings within tiles, which reduces spatiotemporal aliasing significantly. The image quality is verified with a user study. Our work can be used for esports or any kind of rendering where higher frame rates are needed."
        thumbnail: andersson19.png
        banner: andersson19.png
        webpage: https://240hz.org/
    - c15:
        authors:
            - mjalal
            - jspjut
            - bboudaoud
            - mbetke
        title: "SIDOD: A Synthetic Image Dataset for 3D Object Pose Recognition with Distractors"
        conference: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops
        conf-short: WiCV
        location: Long Beach
        month: June 16
        year: 2019
        date: 2019-06-16
        paper: http://openaccess.thecvf.com/content_CVPRW_2019/papers/WiCV/Jalal_SIDOD_A_Synthetic_Image_Dataset_for_3D_Object_Pose_Recognition_CVPRW_2019_paper.pdf
        alternate: https://research.nvidia.com/publication/2019-06_SIDOD%3A-A-Synthetic
        alternate2: http://openaccess.thecvf.com/content_CVPRW_2019/html/WiCV/Jalal_SIDOD_A_Synthetic_Image_Dataset_for_3D_Object_Pose_Recognition_CVPRW_2019_paper.html
        abstract: "We present a new image dataset generated by the NVIDIA Deep Learning Data Synthesizer intended for use in object detection, pose estimation, and tracking applications. This dataset contains 144k stereo image pairs generated from 18 camera view points of three photorealistic virtual environments with up to 10 objects (chosen randomly from the 21 object models of the YCB dataset) and flying distractors.  Object and camera pose, scene lighting, and quantity of objects and distractors were randomized. Each provided view includes RGB, depth, segmentation, and surface normal images. We describe our approach for domain randomization and provide insight into the decisions that produced the dataset."
        thumbnail: jalal19.png
        banner: jalal19.png
    - c14:
        authors:
            - jbarreiros
            - hclaure
            - bpeele
            - oshapira
            - jspjut
            - dluebke
            - mjung
            - rshepherd
        title: Fluidic Elastomer Actuators for Haptic Interactions in Virtual Reality
        conference: IEEE Robotics and Automation Letters (RA-L)
        conf-short: IEEE RA-L
        location: 
        month: February
        year: 2019
        date: 2019-02-27
        paper: https://ieeexplore.ieee.org/abstract/document/8581471
        abstract: "Virtual reality experiences via immersive optics and sound are becoming ubiquitous; there are several consumer systems (e.g., Oculus Rift and HTC Vive) now available with these capabilities. Other sensory experiences, such as that of touch remain elusive in this field. The most successful examples of haptic sensation (e.g., Nintendo 64's rumble pack and its descendants) are vibrotactile, which do not afford for persistent, morphological shape experiences. This letter presents work on the development of a 12 DOF fluidically pressurized soft actuator for persistent and kinesthetic haptic sensations, a hardware controller for operating it, and software interface with NVIDIA's game VR Funhouse."
        thumbnail: barreiros19.png
        banner: barreiros19.png
    - c13:
        authors:
            - amarrs
            - jspjut
            - hgruen
            - rsathe
            - mmcguire
        title: Adaptive Temporal Antialiasing
        conference: High-Performance Graphics (HPG 2018)
        conf-short: HPG
        location: Vancouver
        month: August 10-12
        year: 2018
        date: 2018-08-10
        paper: http://research.nvidia.com/sites/default/files/pubs/2018-08_Adaptive-Temporal-Antialiasing/adaptive-temporal-antialiasing-preprint.pdf
        alternate: http://research.nvidia.com/publication/2018-08_Adaptive-Temporal-Antialiasing
        abstract: We introduce a pragmatic algorithm for real-time adaptive supersampling in games. It extends temporal antialiasing of rasterized images with adaptive ray tracing, and conforms to the constraints of a commercial game engine and today's GPU ray tracing APIs. The algorithm removes blurring and ghosting artifacts associated with standard temporal antialiasing and achieves quality approaching 8X supersampling of geometry, shading, and materials while staying within the 33ms frame budget required of most games.
        thumbnail: marrs18a.png
        banner: marrs18a.png
    - c12:
        authors:
            - kshkurko
            - tgrant
            - elb
            - dkopta
            - jspjut
            - evasiou
            - amallett
            - cyuksel
        title: "SimTrax: Simulation Infrastructure for Exploring Thousands of Cores"
        conference: ACM Great Lakes Symposium on VLSI
        conf-short: GLSVLSI
        month: May 23-25
        year: 2018
        date: 2018-05-23
        paper: http://josef.spjut.me/pubs/shkurko18.pdf
        abstract: "SimTRaX is a simulation infrastructure for simultaneous exploration of highly parallel accelerator architectures and how applications map to them. The infrastructure targets both cycle-accurate and functional simulation of architectures with thousands of simple cores that may share expensive computation and memory resources. A modified LLVM backend used to compile C++ programs for the simulated architecture allows the user to create custom instructions that access proposed special-purpose hardware and to debug and profile the applications being executed. The simulator models a full memory hierarchy including registers, local scratchpad RAM, shared caches, external memory channels, and DRAM main memory, leveraging the USIMM DRAM simulator to provide accurate dynamic latencies and power usage. SimTRaX provides a powerful and flexible infrastructure for exploring a class of extremely parallel architectures for parallel applications that are not easily simulated using existing simulators."
        thumbnail: shkurko18.png
        banner: shkurko18.png
    - c11:
        authors:
        - bmacmurray
        - bpeele
        - patriciaxu
        - jspjut
        - oshapira
        - dluebke
        - rshepherd
        title: A Variable Shape and Variable Stiffness Controller for Haptic Virtual Interactions
        conference:  IEEE International Conference on Soft Robotics
        conf-short: RoboSoft
        month: April 24-28
        year: 2018
        date: 2018-04-24
        paper: http://research.nvidia.com/sites/default/files/pubs/2018-04_A-Variable-Shape/Mac%20Murray%20Final%2020180228.pdf
        abstract: "This paper presents an entirely compliant controller handle for use in virtual and augmented reality environments. The controller handle transitions between two static states: a semi-rigid, large diameter state when pneumatically pressurized and a soft, compressible, smaller diameter state when depressurized. We integrated the controller with a modified version of NVIDIA's VR Funhouse employing the two controller states to simulate the physical feel of two virtual objects. We used finite element modeling to downselect an internal elastomer lattice within the controller that controls deformation upon inflation. Finally, we show an example of using the compliance of the handle as an interaction input by designing an algorithm to identify rapid compressions of the handle as a signal to swap objects in the virtual environment."
        alternate: http://research.nvidia.com/publication/2018-04_A-Variable-Shape
        thumbnail: robosoft2018.png
        banner: macmurray18.png
    - c10:
        authors:
        - tgreer
        - jspjut
        - dluebke
        - jtw
        title: Hybrid Modulation for Near Zero Display Latency
        conference: Society of Information Display
        conf-short: SID
        month: May 24-27
        year: 2016
        date: 2016-05-24
        paper: http://josef.spjut.me/pubs/greer16.pdf
        alternate: http://onlinelibrary.wiley.com/doi/10.1002/sdtp.10614/full
        video: https://www.youtube.com/watch?v=BKzXRwJ8gjw
        abstract: "Binary displays for virtual reality can achieve low latency by integrating view tracking with modulation. We present a novel modulation scheme that combines tracking, pulse density modulation, and pulse width modulation to minimize grayscale artifacts. The hybrid modulator is applied to an AMOLED display at an update rate of 1.7 kHz on which we observe nearly zero latency in the perceived image."
        thumbnail: greer16.png
        banner: greer16.png
    - c9:
        authors:
        - dkopta
        - kshkurko
        - jspjut
        - elb
        - ald
        title: Memory Considerations for Low Energy Ray Tracing
        conference: Computer Graphics Forum
        conf-short: CGF
        month: August 7
        year: 2014
        date: 2014-08-07
        paper: http://onlinelibrary.wiley.com/doi/10.1111/cgf.12458/abstract?systemMessage=Wiley+Online+Library+will+be+disrupted+9th+Aug+from+10-2+BST+for+essential+maintenance.+Pay+Per+View+will+be+unavailable+from+10-6+BST.
        thumbnail: kopta14.png
        banner: kopta14.png
    - c8:
        authors:
        - dkopta
        - kshkurko
        - jspjut
        - elb
        - ald
        title: An Energy and Bandwidth Efficient Ray Tracing Architecture
        conference: High-Performance Graphics (HPG 2013)
        conf-short: HPG
        location: Anaheim
        month: July 10-21
        year: 2013
        date: 2013-07-10
        paper: http://www.cs.utah.edu/~dkopta/papers/hwrt_hpg13.pdf
        thumbnail: kopta13.png
        banner: kopta13.png
    - c7:
        authors:
        - dkopta
        - tize
        - jspjut
        - elb
        - ald
        - aek
        title: 'Fast, Effective BVH Updates for Animated Scenes'
        conference: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D 2012)
        conf-short: I3D
        location: Irvine
        month: March 
        year: 2012
        date: 2012-03-01
        paper: http://josef.spjut.me/pubs/kopta12.pdf
        thumbnail: kopta12.png
        banner: kopta12.png
    - c6:
        authors:
        - jspjut
        - dkopta
        - elb
        - ald
        title: A Mobile Accelerator Architecture for Ray Tracing
        conference: '3rd Workshop on SoCs, Heterogeneous Architectures and Workloads (SHAW-3)'
        conf-short: SHAW
        location: New Orleans
        month: February 
        year: 2012
        date: 2012-02-01
        paper: http://josef.spjut.me/pubs/spjut12.pdf
        slides: http://www.cs.utah.edu/~sjosef/slides/spjut-shaw12-slides.pdf
        thumbnail: spjut12.png
        banner: spjut12.png
    - c5:
        authors:
        - dkopta
        - jspjut
        - ald
        - elb
        title: Efficient MIMD Architectures for High-Performance Ray Tracing
        conference: IEEE International Conference on Computer Design (ICCD 2010)
        conf-short: ICCD
        location: Amsterdam
        month: October 
        year: 2010
        date: 2010-10-01
        paper: http://www.cs.utah.edu/~dkopta/papers/hwrt_iccd10.pdf
        thumbnail: kopta10.png
    - c4:
        authors:
        - spugsley
        - jspjut
        - dnellans
        - rajeev
        title: 'SWEL: Hardware Cache Coherence Protocols to Map Shared Data onto Shared Caches'
        conference: 19th International Conference on Parallel Architectures and Compilation Techniques (PACT-19)
        conf-short: PACT
        location: Vienna
        month: September 
        year: 2010
        date: 2010-09-01
        paper: https://pdfs.semanticscholar.org/ce47/02c907835c14022c9e3052a25c46d459c295.pdf
        thumbnail: pugsley10.png
    - c3: 
        authors:
        - jspjut
        - aek
        - dkopta
        - elb
        title: 'TRaX: A Multicore Architecture for Real-Time Ray Tracing'
        conference: IEEE Transactions on Computer Aided Design of Integrated Circuits and Systems (TCAD)
        conf-short: TCAD
        month: December
        year: 2009
        date: 2009-12-01
        paper: http://www.cs.utah.edu/~dkopta/papers/hwrt_tcad09.pdf
        thumbnail: spjut_tcad09.png
    - c2:
        authors:
        - jspjut
        - aek 
        - elb
        title: Hardware-accelerated gradient noise for graphics
        conference: Proceedings of the 19th ACM Great Lakes Symposium on VLSI (GLSVLSI'09)
        conf-short: GLSVLSI
        location: Boston
        month: May 10-12
        year: 2009
        date: 2009-05-10
        paper: http://www.eng.utah.edu/~cs6958/papers/noise.pdf
        thumbnail: spjut_glsvlsi09.png
    - c1: 
        authors: 
        - nil
        - spugsley
        - jspjut 
        - rajeev
        title: Optimizing a Multi-Core Processor for Message-Passing Workloads
        conference: 5th Workshop on Unique Chips and Systems (UCAS-5)
        conf-short: UCAS
        location: Boston
        month: April
        year: 2009
        date: 2009-04-01
        paper: http://ai2-s2-pdfs.s3.amazonaws.com/f87a/bd4bf77bae5286fbde62de6b331d45c30d0c.pdf
        thumbnail: nil09.png
    - c0: 
        authors: 
        - jspjut 
        - sboulos 
        - dkopta 
        - elb 
        - skellis
        title: "TRaX: A Multi-Threaded Architecture for Real-Time Ray Tracing"
        conference: "Symposium on Application Specific Processors (SASP)"
        conf-short: SASP
        location: Anaheim
        month: June 8-9
        year: 2008
        date: 2008-06-08
        misc: (Best paper award)
        paper: http://www.cs.utah.edu/~dkopta/papers/hwrt_sasp08.pdf
        thumbnail: spjut08.png
---
name: Book Chapter
hugoid: 6
urlid: bc
pubs:
    - bc3:
        authors:
        - jspjut
        - mvance
        title: "Part VI: Performance"
        conference: Ray Tracing Gems II
        conf-short: RTG2
        month: August
        year: 2021
        date: 2021-08-26
        paper: https://link.springer.com/content/pdf/bfm%3A978-1-4842-7185-8%2F6%2F1.pdf
        thumbnail: spjutvance21.png
        banner: spjutvance21.png
        abstract: Though the flm industry may hope to render a frame in sixty seconds, in video games and other interactive applications, we would hope to render sixty frames or more in a single second, leaving scant milliseconds for each image to be produced. This part contains chapters that focus on a variety of topics that explore the optimization space of ray tracing performance, proposing both algorithmic and heuristic improvements to aid in the relentless search for both faster runtime speed as well as smaller memory utilization.
    - bc2:
        authors:
        - rsathe
        - hgruen
        - amarrs
        - jspjut
        - mmcguire
        - yyuralsky
        title: "Adaptive Anti-Aliasing using Conservative Rasterization and GPU Ray Tracing"
        conference: GPU Zen 2
        conf-short: GPU Zen 2
        month: April
        year: 2019
        date: 2019-04-21
        paper: https://www.amazon.com/dp/179758314X
        thumbnail: sathe19.png
        banner: none.png
        abstract: 
    - bc1:
        authors:
        - amarrs
        - jspjut
        - hgruen
        - rsathe
        - mmcguire
        title: Improving Temporal Antialiasing with Adaptive Ray Tracing
        conference: Ray Tracing Gems
        conf-short: RTG
        month: March
        year: 2019
        date: 2019-03-31
        paper: https://link.springer.com/content/pdf/10.1007%2F978-1-4842-4427-2_22.pdf
        alternate: https://research.nvidia.com/publication/2019-03_Improving-Temporal-Antialiasing
        alternate2: https://developer.nvidia.com/books/raytracing/raytracing_gems_preview
        thumbnail: ATAA_RTG19.png
        banner: ATAA_RTG19.png
        abstract: In this chapter, we discuss a pragmatic approach to real-time supersampling that extends commonly used temporal antialiasing techniques with adaptive ray tracing. The algorithm conforms to the constraints of a commercial game engine, removes blurring and ghosting artifacts associated with standard temporal antialiasing, and achieves quality approaching 16x supersampling of geometry, shading, and materials within the 16 ms frame budget required of most games.
---
name: Technical Demos
hugoid: 8
urlid: td
pubs:
    - td6:
        authors:
        - sstokey
        - zchen
        - cmettler
        - dtang
        - mclaypool
        - bboudaoud
        - joohwankim
        - jspjut
        title: "Demonstration of Network Latency and the Peeker's Advantage in First-person Shooter Games"
        conference: Foundations of Digital Games
        conf-short: FDG
        location: Worcester
        month: May
        year: 2024
        date: 2024-05-21
        paper: https://web.cs.wpi.edu/~claypool/papers/peeker-fdg-24/demo-paper.pdf
        thumbnail: tokey24demo.png
        banner: tokey24peek.png
        abstract: We demonstrate peeker's advantage in a first person shooter game.
    - td5:
        authors:
        - bboudaoud
        - pknowles
        - joohwankim
        - jspjut
        title: "Gaming at Warp Speed: Improving Aiming with Late Warp"
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: online
        month: August 9-13
        year: 2021
        date: 2021-08-09
        paper: https://research.nvidia.com/publication/2021-08_Gaming-at-Warp
        thumbnail: boudaoud21etech.png
        banner: boudaoud21etech.png
        abstract: Latency can make all the difference in competitive online games. Late warp is a class of techniques used in VR that can reduce latency in FPS games as well. Prior art has demonstrated these techniques can recover most of the player performance lost to computer or network latency. Inspired by prior work demonstrating the usefulness of late warp as a potential solution to FPS latency, we provide an interactive demonstration, playable in a web browser, that shows how much latency limits aiming performance, and how late warp can help.
    - td4:
        authors:
        - jonghyunkim
        - mstengel
        - juiyiwu
        - bboudaoud
        - jspjut
        - kaksit
        - ralbert
        - tgreer
        - youngmojeong
        - wlopes
        - zmajercik
        - pshirley
        - mmcguire
        - dluebke
        title: "Matching Visual Acuity & Prescription: Towards AR for Humans"
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: Los Angeles
        month: July 28 - August 1
        year: 2019
        date: 2019-07-28
        paper: https://research.nvidia.com/sites/default/files/pubs/2019-07_Matching-Prescription-%26//2019_Etech_submission%20%2815%29.pdf
        alternate: https://research.nvidia.com/publication/2019-07_Matching-Prescription-%26
        thumbnail: etech19.png
        banner: etech19.png
        abstract: "In this installation, we demonstrate two novel wearable augmented reality (AR) prototypes inspired by the understandings on human visual system: Prescription AR and Foveated AR. Prescription AR is a 5mm-thick prescription-embedded AR display based on a free-form image combiner. A plastic prescription lens corrects viewer's vision while a half-mirror-coated free-form image combiner located delivers an augmented image located at the fixed focal depth (1 m). Foveated AR is a near-eye AR display with resolution and focal depth dynamically driven by gaze tracking. The display combines a traveling microdisplay relayed off a concave half-mirror magnifier for the high-resolution foveal region, with a wide FOV peripheral display using a projector-based Maxwellian-view display whose nodal point is translated to follow the viewer's pupil during eye movements using a traveling holographic optical element (HOE). The same optics relay an image of the eye to an infrared camera used for gaze tracking, which in turn drives the foveal display location and peripheral nodal point. Our display supports accommodation cues by varying the focal depth of the microdisplay in the foveal region, and by rendering simulated defocus on the 'always in focus' scanning laser projector used for peripheral display."
    - td3:
        authors:
        - krathinavel
        - pchakravarthula
        - kaksit
        - jspjut
        - bboudaoud
        - jtw
        - dluebke
        - hfuchs
        title: "Steerable Application-Adaptive Near-Eye Displays"
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: Vancouver
        month: August 12 - 16
        year: 2018
        date: 2018-08-12
        misc: (Best in show award)
        paper: https://kaanaksit.com/portfolio/manufacturing-application-driven-near-eye-displays/
        thumbnail: etech18-unc.png
        banner: etech18-unc.png
        abstract: This augmented reality display uses interchangeable 3D-printed optical components to provide content-specific accommodation support. It also presents high-resolution imagery in a gaze-contingent manner by implementing a lens actuation based foveation mechanism.
    - td2:
        authors:
        - kaksit
        - wlopes
        - jonghyunkim
        - jspjut
        - apatney
        - pshirley
        - dluebke
        - scholewiak
        - psrinivasan
        - renng
        - mbanks
        - glove
        title: "Varifocal Virtuality: A Novel Optical Layout for Near-Eye Display"
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: Los Angeles
        month: July 30 - August 3
        year: 2017
        date: 2017-07-30
        paper: http://research.nvidia.com/sites/default/files/publications/final%281%29.pdf
        alternate: http://research.nvidia.com/publication/2017-07_Varifocal-Virtuality%3A-A
        slides: https://kaanaksit.files.wordpress.com/2017/08/siggraph_slides.pdf
        thumbnail: etech17-nv.png
        banner: etech17-nv.png
        abstract: Augmented reality (AR) has recently gained momentum in the form of a variety of available optical see-through near-eye displays (NEDs) such as the Meta 2and the Microsoft Hololens. These devices are a big step forward towards Sutherland's vision of an ultimate display [Sutherland 1968]. The device we demonstrate attempts to deal with the main limitations of current devices. First, the graphics images are at a constant virtual distance for the eyes' accommodation mechanism, while the vergence of the two eyes working in concert places the virtual object(s) at a distance other than the accommodation distance. This vergence-accommodation conflict is one of the main problems in many AR and VR systems [Kress and Starner 2013]. The second limitation is achieving a wide FOV with compact optics. Cakmakci et al. [2006] contend that achieving a wide field-of-view (FOV) is the major optical design challenge in AR NEDs.
    - td1:
        authors:
        - rshepherd
        - bpeele
        - bmacmurray
        - jbarreiros
        - oshapira
        - jspjut
        - dluebke
        title: Stretchable Transducers for Kinesthetic Interactions in Virtual Reality
        conference: SIGGRAPH Emerging Technologies
        conf-short: SIGGRAPH E-Tech
        location: Los Angeles
        month: July 30 - August 3
        year: 2017
        date: 2017-07-30
        paper: http://research.nvidia.com/sites/default/files/publications/peele_siggraph_etech17.pdf
        alternate: http://research.nvidia.com/publication/2017-06_Stretchable-Transducers-for
        thumbnail: etech17-orl-3.png
        banner: etech17-orl-2.png
        abstract: We provide two key demonstrations to highlight the use of fluidic elastomer actuators to provide haptic feedback. These demos allow users to progress through a series of brief experiences where the hand-held controller adjusts its form and behavior to match that of the virtual object used in each demo. The objects held in the demo include a goo gun, pistol and mallet.
    - td0:
        authors:
        - bpeele
        - bmacmurray
        - jbarreiros
        - rshepherd
        - oshapira
        - jspjut
        - dluebke
        title: Stretchable Transducers for Haptic Interactions in Virtual and Augmented Reality
        conference: GPU Technology Conference VR Village
        conf-short: GTC
        location: San Jose
        month: May 9 - 11
        year: 2017
        date: 2017-05-09
        thumbnail: etech17-orl.png
        banner: etech17-orl-2.png
---
name: Conference Talks and Courses
hugoid: 9
urlid: ct
pubs:
    - ct13:
        authors:
            - dklein
            - jspjut
            - bboudaoud
            - joohwankim
        title: "On Smoothly Varying Frame Timing in First-Person Gaming"
        conference: SIGGRAPH Talk
        conf-short: SIGGRAPH Talk
        location: Denver
        month: July 28
        year: 2024
        date: 2024-07-28
        paper: https://dl.acm.org/doi/abs/10.1145/3641233.3664346
        thumbnail: klein24talk.png
        banner: none.png
        abstract: "Some researchers have used G-Sync as a part of stimulus design [Poth et al. 2018], or to promote energy savings [Ko 2019; You et al. 2020]. Others have used VRR as a method for shifting refresh rates to match a perceptual goal, but neglected to study the impact of varying the refresh rate itself [Denes et al. 2020; Jindal et al. 2021]. More directly related works study VRR's effect on task performance, some showing positive general outcomes [Riahi and Watson 2021; Watson et al. 2019], while others have focused on the perceptual effects (quality of experience) when artificially adding variability [Liu et al. 2023]. None of these studies carefully control the frame time sequence and distribution, nor study rates above 120 Hz. Our study fills these gaps using a smoothly varying controlled sequence, including stimuli up to 240 Hz."
    - ct12:
        authors:
            - amadhusudan
            - jspjut
            - bboudaoud
            - joohwankim
            - bwatson
        title: "Studying Esports Competition: Piloting Methodology for User Studies During Tournaments"
        conference: SIGGRAPH Talk
        conf-short: SIGGRAPH Talk
        location: Denver
        month: July 28
        year: 2024
        date: 2024-07-28
        paper: https://dl.acm.org/doi/abs/10.1145/3641233.3664349
        thumbnail: madhusudan24talk.png
        banner: none.png
        abstract: "Designing experiments is a well-studied, complex task with many conflicting constraints. In experimental user studies, the overarching goal is to gain understanding of how a system affects users by manipulating independent variables (eg, an interface's configuration) while measuring dependent variables (eg, the user's performance). Achieving this goal requires significant compromise between many conflicting sub-goals including internal validity, that the effects on dependent variables were caused by manipulations of independent variables, not other uncontrolled variables; external validity, that the findings are generalizable enough to have meaning outside the lab; and feasibility, that the experiment can be performed without unreasonable time and cost."
    - ct11:
        authors:
            - dyuen
            - jspjut
        title: "Experimenting with Artificial Intelligence: Programming Pathfinding Algorithms in C++ with Unreal Engine 5"
        conference: SIGGRAPH Labs Course
        conf-short: SIGGRAPH Labs
        location: Denver
        month: July 28
        year: 2024
        date: 2024-07-28
        paper: https://dl.acm.org/doi/abs/10.1145/3641236.3664419
        thumbnail: yuen24.png
        banner: none.png
        abstract: "Recent years have seen a rise in machine learning applications deployed in different technological contexts. It has shaped how we experience technology and led to new doors of innovation and a mass market interest in artificial intelligence (AI)."
    - ct10:
        authors:
            - zoexu
            - jspjut
            - bboudaoud
            - sbuetti
            - alleras
            - rrosenholtz
        title: "Do Action Video Game Players Search Faster Than Non-Players?"
        conference: Vision Science Society
        conf-short: VSS
        location: St. Pete Beach
        month: May 18
        year: 2024
        date: 2024-05-18
        paper: https://jov.arvojournals.org/article.aspx?articleid=2801490
        thumbnail: xu24.png
        banner: none.png
        abstract: "Studies have shown that action video game players have enhanced visual abilities in various domains, such as multiple object tracking, size of the useful field of view, and visual search speed and accuracy. These improvements have been attributed to either a general advantage in ''learning to learn'' abilities, or domain-specific enhancement(s) in the ''common demands'' between specific games and experimental tasks. To investigate these two theories, we conducted six experiments examining whether and how players and non-players differ in various aspects of visual search. First, we used a staircase to determine the minimal display duration (Experiment1a) and target-distractor color difference (Experiment1b) required for participants to successfully identify a target in a color search task. Next, we assessed participants' search speed and the cost of switching target and distractor identities when there is one (Experiment2a) or multiple distractor types (Experiment2b). Finally, we measured search speed in harder T/L search (Experiment3a) and game-style figure search (Experiment3b). This study is the first to use both a staircase procedure and standard response time measures to discern differences between players and non-players in visual search. The results suggest that players search faster than non-players only in Experiment2, where performance degraded with increased distractor variability for non-players but not for players. Players also exhibited a smaller cost to switching the target and distractor identities. These findings imply that while there might be no overall enhancement in players' search abilities, they might benefit from holding variable distractor templates and switching their search target, potentially due to gaming experience which often necessitates memorizing and switching among multiple objects to monitor/avoid (as in first-person shooting games). These results support the ''common demands'' theory. In addition, our collected data on the specific games participants play allow for a more systematic evaluation of which games might enhance which search-related abilities."
    - ct9:
        authors:
            - jspjut
            - bboudaoud
            - joohwankim
        title: Constant Field of View Display Size Effects on First-Person Aiming Time
        conference: Frontiers in Optics + Laser Science
        conf-short: FiO
        location: Tacoma
        month: October 9
        year: 2023
        date: 2023-10-09
        paper: http://josef.spjut.me/pubs/spjut23fio.pdf
        alternate: https://research.nvidia.com/publication/2023-10_constant-field-view-display-size-effects-first-person-aiming-time
        alternate2: https://opg.optica.org/viewmedia.cfm?uri=FiO-2023-FTu6A.1
        thumbnail: spjut23b.png
        banner: spjut23b.png
        abstract: "Under constant display field of view, FPS game aiming performance improves with display size, resulting in 3% faster aiming time comparing 13 and 26 inches diagonal."
    - ct8:
        authors:
            - joohwankim
            - jspjut
            - bboudaoud
            - bwatson
            - jtw
        title: Rethinking Display Requirements for Esports and High Interactivity Applications
        conference: Society for Information Display
        conf-short: SID
        location: San Francisco
        month: August 30
        year: 2023
        date: 2023-08-30
        paper: https://sid.onlinelibrary.wiley.com/doi/abs/10.1002/sdtp.16538
        alternate: https://research.nvidia.com/publication/2023-08_rethinking-display-requirements-esports-and-high-interactivity-applications
        thumbnail: spjut23b.png
        banner: none.png
        abstract: "Under constant display field of view, FPS game aiming performance improves with display size, resulting in 3% faster aiming time comparing 13 and 26 inches diagonal."
    - ct7:
        authors:
            - bwatson
            - joohwankim
            - jspjut
            - pshirley
            - blee
        title: "Less is More: Rendering for Esports"
        conference: SIGGRAPH Frontiers Workshop
        conf-short: SIGGRAPH Workshop
        location: Los Angeles
        month: August 7
        year: 2023
        date: 2023-08-07
        paper:
        thumbnail: watson23.png
        banner: none.png
        abstract: "Computer graphics has improved from early wireframes to ray tracing and physically based rendering. Yet nearly 20 years ago, George Lucas stated that ``the real leap has been made,'' and today, esports players turn off many of the rendering techniques that took SIGGRAPH so long to develop, because they don't help them win. Is it time for SIGGRAPH to reconsider its research goals? This workshop will discuss this question, including alternatives to photorealism, trading off temporal and visual accuracy, and trading off realism with gameplay and fairness. The workshop will prioritize participant discussion, fomented by short provocative talks."
    - ct6:
        authors:
            - bwatson
            - jspjut
            - blee
            - gward
        title: "FirstPersonScience: An Open Source Tool for Studying FPS Esports Aiming"
        conference: SIGGRAPH Frontiers Workshop
        conf-short: SIGGRAPH Workshop
        location: Vancouver
        month: August 10
        year: 2022
        date: 2022-08-10
        paper: https://research.nvidia.com/publication/2022-08_esports-frontier-rendering-interaction-and-display
        alternate: https://research.nvidia.com/publication/2022-08_esports-frontier-rendering-interaction-and-display
        thumbnail: watson22.png
        banner: none.png
        abstract: "The history of computer graphics is dominated by the quest for photorealism. Yet esports gamers have not benefited from the results, regularly turning off all visual effects to maximize frame rate. How can the SIGGRAPH community better support the expert performance esports athletes seek? This is not an idle question: esports now rivals traditional sports in both viewership and revenue, and is already driving demand for new, high-performance displays and mice. This workshop will examine the challenges involved in finding the answers, including innovation in display, rendering and interaction."
    - ct5:
        authors:
            - bboudaoud
            - jspjut
            - pknowles
            - amadhusudan
            - joohwankim
        title: "FirstPersonScience: An Open Source Tool for Studying FPS Esports Aiming"
        conference: SIGGRAPH Talk
        conf-short: SIGGRAPH Talk
        location: Online
        month: August 8
        year: 2022
        date: 2022-08-08
        paper: https://d1qx31qr3h6wln.cloudfront.net/publications/S2022_Talk_FPSci.pdf
        alternate: https://research.nvidia.com/index.php/publication/2022-08_firstpersonscience-open-source-tool-studying-fps-esports-aiming
        thumbnail: boudaoud22c.png
        banner: none.png
        abstract: First-person shooters (FPS) games are dominant in the competitive gaming and esports community. However, relatively few tools are available for experimenters interested in studying mechanics of these games in a controlled, repeatable environment. While other researchers have made progress with one-off applications as well as custom content and mods for existing games, we are not aware of a general purpose application for empirically studying a broad set of user interactions in the FPS context. For the past few years our team has developed, maintained, and deployed First Person Science (FPSci), a tool for controlled user studies in FPS gaming. FPSci experimenters configure their desired base environment, as well as conditions and user preferences using a simplified JSON-esque set of input configurations, and results are stored in an SQLite database. By allowing finer grained parametric control of the environment together with frame-wise logging of player state and performance metrics, we achieve a level of granularity of control not offered by other solutions. FPSci is available as an open source project.
    - ct4:
        authors:
            - bwatson
            - jspjut
            - cmcgee
            - aissa
            - wmackey
        title: "Esports as a Driving Problem in Computer Graphics"
        conference: SIGGRAPH Panel
        conf-short: SIGGRAPH Panel
        location: Online
        month: August 9-13
        year: 2021
        date: 2021-08-09
        paper: http://josef.spjut.me/pubs/watson21.pdf
        thumbnail: watson21.png
        banner: none.png
        abstract: Esports is a growing worldwide phenomenon now rivaling traditional sports, with a deep dependence on real-time graphics technology. Despite this, the SIGGRAPH research community has largely ignored it. This panel brings together esports experts in engineering, medicine as well as cognitive and data science to argue that this must change. Like film, esports is an important problem for computer graphics, and could give rise to technologies and techniques benefitting not only esports, but society more broadly. With a series of moderated and audience questions, this panel will sketch the research challenges and potential benefits of esports, while also considering its risks.
    - ct3:
        authors:
        - jspjut
        - bboudaoud
        title: "Foveated Displays: Toward Classification of the Emerging Field"
        conference: SIGGRAPH Talk
        conf-short: SIGGRAPH Talk
        location: Los Angeles
        month: July 28-31
        year: 2019
        date: 2019-07-28
        paper: https://doi.org/10.1145/3306307.3328145
        slides: https://drive.google.com/file/d/1-2-QUoRtV2AUTg3we-88sn8-D797ir8H/view?usp=sharing
        thumbnail: spjutfdt19.png
        banner: spjutfdt19.png
        abstract: There is not yet consensus in the field on what constitutes a ``foveated display''. We propose a compromise between the perspectives of rendering, imaging, physiology and vision science that defines a foveated display as a display designed to function in the context of user gaze. This definition enables us to describe 2 axes of foveation, gaze interaction and resolution distribution, which we then subdivide to provide useful categories for classification. We view this proposal as the start of a discussion among the community rather than a final taxonomy.
    - ct2:
        authors:
        - jspjut
        title: "The Augmented Frontier: Challenges for Near Eye Display Computing"
        conference: "[AR In Action](http://arinaction.org/)"
        conf-short: ARIA
        location: Boston
        month: January 16-17
        year: 2018
        date: 2018-01-16
        paper: http://josef.spjut.me/pubs/spjutARIA2018.pdf
        video: https://www.youtube.com/watch?v=sIqv-MJAwHo
        thumbnail: spjutaria18.png
        banner: nvresearch.png
        abstract: NVIDIA Research is developing solutions to upcoming difficulties for near eye displays for virtual and augmented reality. In this talk, I review some of the recent research projects from NVIDIA and our collaborators at various insitutions and how they contribute to our greater vision of near eye display computing replacing the existing ecosystem of mobile and desktop computing. 
        details: See also [The Virtual Fronteir](http://on-demand.gputechconf.com/siggraph/2017/video/sig1718-morgan-mcguire-virtual-frontier-computer-graphics.html) by Morgan McGuire from whom I borrowed many of the slides.
    - ct1:
        authors:
        - bpeele
        - bmacmurray
        - rshepherd
        - jbarreiros
        - oshapira
        - jspjut
        - dluebke
        title: Stretchable Transducers for Kinesthetic Interactions in Virtual Reality
        conference: SIGGRAPH Experience Presentations
        conf-short: SIGGRAPH Talk
        location: Los Angeles
        month: August 3
        year: 2017
        date: 2017-08-03
        paper: http://research.nvidia.com/sites/default/files/publications/peele_siggraph_etech17.pdf
        alternate: http://research.nvidia.com/publication/2017-06_Stretchable-Transducers-for
        thumbnail: etech17-orl-4.png
        banner: etech17-orl.png
        abstract: We provide two key demonstrations to highlight the use of fluidic elastomer actuators to provide haptic feedback. These demos allow users to progress through a series of brief experiences where the hand-held controller adjusts its form and behavior to match that of the virtual object used in each demo. The objects held in the demo include a goo gun, pistol and mallet.
    - ct0:
        authors:
        - jspjut
        - rpiersall
        - klau
        title: Build your own game controller
        conference: SIGGRAPH Studio
        conf-short: SIGGRAPH Studio
        location: Los Angeles
        month: August 10
        year: 2015
        date: 2015-08-10
        misc: (Studio Course)
        slides: http://josef.spjut.me/class/controllerCourseNotes.pdf
        webpage: http://josef.spjut.me/class/game-controller
        thumbnail: spjut15.jpg
        banner: spjut15.jpeg
---
name: Dissertation
hugoid: 10
urlid: dis
pubs:
    - d0:
        authors:
        - jspjut
        title: "Efficient Ray Tracing Architectures"
        conference: "University of Utah Dissertation"
        conf-short: Dissertation
        month: May
        year: 2015
        date: 2015-05-01
        paper: http://josef.spjut.me/pubs/thesis.pdf
        alternate: http://gradworks.umi.com/3727095.pdf
        alternate2: http://content.lib.utah.edu/cdm/ref/collection/etd3/id/3732
        thumbnail: spjut-dis.png
        banner: spjut-dis.png
        abstract: "This dissertation presents computer architecture designs that are efficient for ray tracing based rendering algorithms. The primary observation is that ray tracing maps better to independent thread issue hardware designs than it does to dependent thread and data designs used in most commercial architectures. While the independent thread issue causes extra overhead in the fetch and issue parts of the pipeline, the number of computation resources required can be reduced through the sharing of less frequently used execution units. Furthermore, since all the threads run a single program on multiple data (SPMD), thread processors can share instruction and data caches. Ray tracing needs read-only access to the scene data during each frame, so caches can be optimized for reading, and traditional cache coherence protocols are unnecessary for maintaining coherent memory access. The resultant image exists as a write only frame buffer, allowing memory writes to avoid the cache entirely, preventing cache pollution and increasing the performance of smaller caches.
        Commercial real-time rendering systems lean heavily on high-performance graphics processing units (GPU) that use the rasterization and z-buffer algorithms for rendering. A single pass of rasterization throws out much of the global scene information by streaming the surface data that a ray tracer keeps resident in memory. As a result, ray tracing is more naturally able to support rendering effects involving global information, such as shadows, reflections, refractions and camera lens effects. Rasterization has a time complexity of approximately O(Nlog(P)) where N is the number of primitive polygons and P is the number of pixels in the image. Ray tracing, in contrast, has a time complexity of O(Plog(N)) making ray tracing scale better to large scenes with many primitive polygons, allowing for increased surface detail. Finally, once the number of pixels reaches its limit, ray tracing should exceed the performance of rasterization by allowing the number of objects to increase with less of a penalty on performance."
---
name: Patents
hugoid: 12
urlid: pat
pubs:
    - pat12:
        authors:
            - jonghyunkim
            - bboudaoud
            - mstengel
            - jspjut
            - mmcguire
        title: "Modular prescription augmented reality display"
        year: 2023
        date: 2023-08-10
        misc: Pending
        paper: https://patents.google.com/patent/US20230251508A1/en
        abstract: "In an embodiment, a modular augmented reality display is provided that incorporates prescription eyewear that can be used separately by the wearer. In an embodiment, an image is generated from a removable display attached to the eyewear and directed into the edge of a prescription lens, which acts as a waveguide. The image is internally reflected within the prescription lens, and is directed to the wearer by an image combiner embedded within the prescription lens. In an embodiment, the augmented reality display includes a wearable belt pouch that includes a battery and support electronics connected to the eyewear so that the weight on the eyewear is reduced."
    - pat11:
        authors:
            - joohwankim
            - jspjut
        title: "Cheat detection by comparing mouse input and frame buffer"
        year: 2023
        date: 2023-08-03
        misc: Pending
        paper: https://patents.google.com/patent/US20230241512A1/en
        abstract: "The disclosure provides a cheating detection strategy for interactive programs, which detects programmatically-generated motion from actual human-generated motion based on a comparison of actual motion data to inferred motion data. The cheating detection strategy uses visual and input information to ensure that the input matches the output to detect and avoid cheating tools positioned in between the input and the output. In one example, the disclosure provide a method of monitoring cheating in interactive programs that includes: (1) receiving actual motion data from a user input device, wherein the actual motion data corresponds to interacting with the interactive program, (2) receiving image data of the interactive program that includes image sequences of the interactive program to display on a screen, (3) comparing the actual motion data to inferred motion data determined from the image sequences, and (4) determining possible cheating based on the comparing."
    - pat10:
        authors:
            - jspjut
        title: "Game cheat detection from mouse lifting"
        year: 2023
        date: 2023-08-03
        misc: Pending
        paper: https://patents.google.com/patent/US20230241513A1/en
        abstract: "A method, system, and computer program product for mouse lift cheat detection are provided. In one embodiment, the method includes receiving mouse movement data from a mouse device and determining if a distance represented by the mouse movement data can be performed by a human. When the distance cannot be performed by a human, the method further includes determining if a mouse lift pattern exists. When the mouse lift pattern exists, the method further includes determining if the distance can be performed by a human considering the mouse lift pattern. An alert is generated when the distance represented by the mouse movement cannot be performed by a human whether the mouse lift pattern exists or not. The alert is not generated when the distance represented by the mouse movement data can be performed by a human whether the mouse lift pattern exists or not."
    - pat9:
        authors:
            - joohwankim
            - bboudaoud
            - jspjut
        title: "Target-based mouse sensitivity recommendations"
        year: 2022
        date: 2023-10-31
        misc: Granted
        paper: https://patents.google.com/patent/US20220203230A1/en
        abstract: "One embodiment of a computer-implemented method for generating mouse sensitivity recommendations includes generating mouse movement data corresponding to one or more mouse movements performed by a user while interacting with a software application; generating a predicted efficiency for each mouse sensitivity level included in a plurality of mouse sensitivity levels based on the mouse movement data; and determining one or more mouse sensitivity levels to provide to the user based on the predicted efficiencies."
    - pat8:
        authors:
            - amarrs
            - jspjut
            - hgruen
            - mmcguire
            - rsathe
        title: "Adding greater realism to a computer-generated image by smoothing jagged edges"
        year: 2021
        date: 2022-12-31
        misc: Pending
        paper: https://patents.google.com/patent/US20210398253A1/en
        abstract: "During the rendering of an image, specific pixels in the image are identified where antialiasing would be helpful. Antialiasing is then performed on these identified pixels, where anti-aliasing is a technique used to add greater realism to a digital image by smoothing jagged edges. This reduces a cost of performing antialiasing by reducing a number of pixels within an image on which antialiasing is performed."
    - pat7:
        authors:
            - joohwankim
            - bboudaoud
            - jspjut
            - mmcguire
            - sschneider
            - rdimitrov
            - lnordskog
            - crobson
            - keithli
            - gslavenburg
            - tverbeure
        title: "System-latency-aware display device"
        year: 2020
        date: 2023-10-10
        misc: Granted
        paper: https://patents.google.com/patent/US20210243101A1/en
        abstract: "A display device for measuring the end-to-end latency of a computing system. The computing system includes an input device, a computing device, and the display device. The display device is directly connected with the input device and receives input data packets generated by the input device in response to received user input events. The display device passes the input packets to the computing device for graphics processing. The display device measures the end-to-end latency comprising the sum of three latencies. A first latency comprises an input delay of the input device. A second latency comprises an amount of time between generation of the input packet and a corresponding change in pixel values caused by the input event at the display device. A third latency comprises a display latency. The display device also displays latency information associated with the measured end-to-end latency."
    - pat6:
        authors:
            - jonghyunkim
            - bboudaoud
            - mstengel
            - jspjut
            - mmcguire
        title: "Modular prescription augmented reality display"
        year: 2022
        date: 2024-01-02
        misc: Granted
        paper: https://patents.google.com/patent/US20210181533A1/en
        abstract: "In an embodiment, a modular augmented reality display is provided that incorporates prescription eyewear that can be used separately by the wearer. In an embodiment, an image is generated from a removable display attached to the eyewear and directed into the edge of a prescription lens, which acts as a waveguide. The image is internally reflected within the prescription lens, and is directed to the wearer by an image combiner embedded within the prescription lens. In an embodiment, the augmented reality display includes a wearable belt pouch that includes a battery and support electronics connected to the eyewear so that the weight on the eyewear is reduced."
    - pat5:
        authors:
            - pknowles
            - bboudaoud
            - jspjut
            - mmcguire
            - kbinaee
            - joohwankim
            - hvutukuru
        title: "Hardware acceleration and event decisions for late latch and warp in interactive computer products"
        year: 2023
        date: 2023-05-30
        misc: Granted
        paper: https://patents.google.com/patent/US20210106912A1/en
        alternate: https://patents.google.com/patent/US11660535B2/en
        abstract: "The disclosure provides features or schemes that improve a user's experience with an interactive computer product by reducing latency through late latching and late warping. The late warping can be applied by imaging hardware based on late latch inputs and is applicable for both local and cloud computing environments. In one aspect, the disclosure provides a method of operating an imaging system employing late latching and late warping. In one example the method of operating an imaging system includes: (1) rendering a rendered image based on a user input from an input device and scene data from an application engine, (2) obtaining a late latch input from the input device, (3) rendering, employing imaging hardware, a warped image by late warping at least a portion of the rendered image based on the late latch input, and (4) updating state information in the application engine with late latch and warp information."
    - pat4:
        authors:
            - joohwankim
            - jspjut
            - ifrosio
            - ogallo
            - eprashnani
        title: "Gaze determination using one or more neural networks"
        year: 2019
        date: 2023-12-31
        misc: Pending
        paper: https://patents.google.com/patent/US20210132688A1/en
        abstract: "Apparatuses, systems, and techniques are presented to modify media content using inferred attention. In at least one embodiment, a network is trained to predict a gaze of one or more users on one or more image features based, at least in part, on one or more prior gazes of the one or more users, wherein the prediction is to be used to modify at least one of the one or more image features."
    - pat3:
        authors:
            - pandersson
            - takeninemoller
            - jnilsson
            - msalvi
            - jspjut
        title: "Reconstruction for temporally dense ray trace rendering"
        year: 2021
        date: 2021-09-14
        misc: Granted
        paper: https://patents.google.com/patent/US20200312010A1/en
        abstract: "A method dynamically selects one of a first sampling order and a second sampling order for a ray trace of pixels in a tile where the selection is based on a motion vector for the tile. The sampling order may be a bowtie pattern or an hourglass pattern. Subframes generated based on the sampling order are communicated over a bus along with motion vectors for tiles of the subframes."
    - pat2:
        authors:
            - hgruen
            - amarrs
            - jspjut
            - rsathe
            - mmcguire
        title: "Adding greater realism to a computer-generated image by smoothing jagged edges within the image in an efficient manner"
        year: 2022
        date: 2022-12-31
        misc: Pending
        paper: https://patents.google.com/patent/US20190318455A1/en
        abstract: "During the rendering of an image, specific pixels in the image are identified where antialiasing would be helpful. Antialiasing is then performed on these identified pixels, where antialiasing is a technique used to add greater realism to a digital image by smoothing jagged edges. This reduces a cost of performing antialiasing by reducing a number of pixels within an image on which antialiasing is performed."
    - pat1:
        authors:
            - amarrs
            - jspjut
            - hgruen
            - mmcguire
            - rsathe
        title: "Adding greater realism to a computer-generated image by smoothing jagged edges"
        year: 2021
        date: 2021-09-07
        misc: Granted
        paper: https://patents.google.com/patent/US20190318454A1/en
        alternate: https://patents.google.com/patent/US11113790B2/en
        abstract: "During the rendering of an image, specific pixels in the image are identified where antialiasing would be helpful. Antialiasing is then performed on these identified pixels, where anti-aliasing is a technique used to add greater realism to a digital image by smoothing jagged edges. This reduces a cost of performing antialiasing by reducing a number of pixels within an image on which antialiasing is performed."
    - pat0:
        authors:
            - tgreer
            - jspjut
            - dluebke
        title: "Retina space display stabilization and a foveated display for augmented reality"
        year: 2021
        date: 2021-03-16
        misc: Granted
        paper: https://patents.google.com/patent/US20190302883A1/en
        abstract: "Perceived clarity of an image presented by a display can be improved using an image stabilization technique to stabilize the image relative to a user's retina. During an illumination period, stabilization actuators are controlled to move a display panel or adjust optical components in the path of light associated with the image to shift the location of the image on the user's retina in response to head or eye movement detected by the system. In some embodiments, a display is configured to illuminate an image, and at least one stabilization actuator is configured to stabilize the image in a retina space associated with a user. Changes in the retina space can be detected by one or more sensors configured to detect a head position of the user and/or an orientation of the user's retina. The image is stabilized in retina space using the stabilization actuators."
---
name: Technical Reports
hugoid: 4
urlid: tr
pubs:
    - tr18:
        authors:
             - azook
             - fysun
             - jspjut
             - vblukis
             - sbirchfield
             - jtremblay
        title: "GRS: Generating Robotic Simulation Tasks from Real-World Images"
        conference: Tech Report
        conf-short: Tech Report
        month: October 24
        year: 2024
        date: 2024-10-24
        paper: https://arxiv.org/abs/2410.15536
        abstract: "We introduce GRS (Generating Robotic Simulation tasks), a novel system to address the challenge of real-to-sim in robotics, computer vision, and AR/VR. GRS enables the creation of digital twin simulations from single real-world RGB-D observations, complete with diverse, solvable tasks for virtual agent training. We use state-of-the-art vision-language models (VLMs) to achieve a comprehensive real-to-sim pipeline. GRS operates in three stages: 1) scene comprehension using SAM2 for object segmentation and VLMs for object description, 2) matching identified objects with simulation-ready assets, and 3) generating contextually appropriate robotic tasks. Our approach ensures simulations align with task specifications by generating test suites designed to verify adherence to the task specification. We introduce a router that iteratively refines the simulation and test code to ensure the simulation is solvable by a robot policy while remaining aligned to the task specification. Our experiments demonstrate the system's efficacy in accurately identifying object correspondence, which allows us to generate task environments that closely match input environments, and enhance automated simulation task generation through our novel router mechanism."
        thumbnail: zook24.png
        banner: none.png
    - tr17:
        authors:
            - shengzewang
            - xuetingli
            - cliu
            - mchan
            - mstengel
            - jspjut
            - hfuchs
            - sdemello
            - knagano
        title: Coherent 3D Portrait Video Reconstruction via Triplane Fusion
        conference: Tech Report
        conf-short: Tech Report
        month: May 1
        year: 2023
        date: 2023-05-01
        paper: https://arxiv.org/pdf/2405.00794
        webpage: https://research.nvidia.com/labs/amri/projects/stable3d/
        alternate: https://arxiv.org/abs/2405.00794
        abstract: "Recent breakthroughs in single-image 3D portrait reconstruction have enabled telepresence systems to stream 3D portrait videos from a single camera in real-time, potentially democratizing telepresence. However, per-frame 3D reconstruction exhibits temporal inconsistency and forgets the user's appearance. On the other hand, self-reenactment methods can render coherent 3D portraits by driving a personalized 3D prior, but fail to faithfully reconstruct the user's per-frame appearance (e.g., facial expressions and lighting). In this work, we recognize the need to maintain both coherent identity and dynamic per-frame appearance to enable the best possible realism. To this end, we propose a new fusion-based method that fuses a personalized 3D subject prior with per-frame information, producing temporally stable 3D videos with faithful reconstruction of the user's per-frame appearances. Trained only using synthetic data produced by an expression-conditioned 3D GAN, our encoder-based method achieves both state-of-the-art 3D reconstruction accuracy and temporal consistency on in-studio and in-the-wild datasets."
        thumbnail: swang24.png
        banner: none.png
    - tr16:
        authors:
            - dklein
            - jspjut
            - bboudaoud
            - joohwankim
        title: The Influence of Variable Frame Timing on First-Person Gaming
        conference: Tech Report
        conf-short: Tech Report
        month: June 2
        year: 2023
        date: 2023-06-02
        paper: https://arxiv.org/pdf/2306.01691
        alternate: https://arxiv.org/abs/2306.01691
        abstract: "Variable frame timing (VFT), or changes in the time intervals between discrete frame images displayed to users, deviates from our traditional conceptualization of frame rate in which all frame times are equal. With the advent of variable refresh rate (VRR) monitor technologies, gamers experience VFT at the display. VRR, coupled with increased display refresh rates and high-end hardware, enables smoother variation of frame presentation sequences. We assess the effects of VFT on the perception of smoothness (experiment 1) and performance (experiment 2) in first-person shooter (FPS) gameplay by introducing frequent but relatively small (4-12 ms) variations in frame time around typical refresh rates (30-240 Hz). Our results indicate that VFT impacts the perception of smoothness. However, the results from experiment 2 do not indicate differences in FPS task performance (i.e., completion time) between variable and constant frame time sequences ranked equally smooth in experiment 1."
        thumbnail: klein23.png
        banner: klein23.png
    - tr15:
        authors:
            - jspjut
            - amadhusudan
            - bwatson
            - sschneider
            - bboudaoud
            - joohwankim
        title: Toward Understanding Display Size for FPS Esports Aiming
        conference: Tech Report
        conf-short: Tech Report
        month: May 26
        year: 2023
        date: 2023-05-26
        paper: https://arxiv.org/pdf/2305.16953
        alternate: https://arxiv.org/abs/2305.16953
        abstract: "Gamers use a variety of different display sizes, though for PC gaming in particular, monitors in the 24 to 27 inch size range have become most popular. Particularly popular among many PC gamers, first person shooter (FPS) games represent a genre where hand-eye coordination is particularly central to the player's performance in game. In a carefully designed pair of experiments on FPS aiming, we compare player performance across a range of display sizes. First, we compare 12.5 inch, 17.3 inch and 24 inch monitors on a multi-target elimination task. Secondly, we highlight the differences between 24.5 inch and 27 inch displays with a small target experiment, specifically designed to amplify these small changes. We find a small, but statistically significant improvement from the larger monitor sizes, which is likely a combined effect between monitor size, resolution, and the player's natural viewing distance."
        thumbnail: spjut23.png
        banner: none.png
    - tr14:
        authors:
            - jspjut
            - amadhusudan
            - bwatson
            - bboudaoud
            - joohwankim
        title: "The Esports Frontier: Rendering for Competitive Games"
        conference: Tech Report
        conf-short: Tech Report
        month: August 24
        year: 2022
        date: 2022-08-24
        paper: https://arxiv.org/pdf/2208.11774
        alternate: https://arxiv.org/abs/2208.11774
        abstract: "Real-time graphics is commonly thought of as anything exceeding about 30 fps, where the interactivity of the application becomes fluid enough for high rates of interaction. Inspired by esports and competitive gaming, where players regularly exceed the threshold for real-time by 10x (esports displays commonly reach 360 Hz or beyond), this talk begins the exploration of how rendering has the opportunity to evolve beyond the current state of focus on either image quality or frame rate. Esports gamers regularly decline nearly all options for increased image quality in exchange for maximum frame rates. However, there remains a distinct opportunity to move beyond the focus on video as a sequence of images and instead rethink the pipeline for more continuous updates."
        thumbnail: spjut22b.png
        banner: none.png
    - tr13:
        authors:
            - bboudaoud
            - jspjut
            - joohwankim
        title: Mouse Sensitivity Effects in First-Person Targeting Tasks
        conference: Tech Report
        conf-short: Tech Report
        month: March 22
        year: 2022
        date: 2022-03-22
        paper: https://arxiv.org/pdf/2203.12050
        alternate: https://arxiv.org/abs/2203.12050
        abstract: "Despite billions of hours of play and copious discussion online, mouse sensitivity recommendations for first-person targeting tasks vary by a factor of 10x or more and remain an active topic of debate in both competitive and recreational gaming communities. Inspired by previous academic literature in pointer-based gain optimization, we conduct the first user study of mouse sensitivity in first person targeting tasks, reporting a statistically significant range of optimal values in both task completion time and throughput. Due to inherent incompatibility (i.e., lack of convert-ability) between sensitivity metrics adopted for prior pointer-based gain literature and those describing first-person targeting, we provide the first analytically demonstrated, statistically significant optimal sensitivity range useful for first-person camera controls. Furthermore, we demonstrate that this optimal sensitivity range arises (at least in part) from a speed-precision trade-off impacted by spatial task difficulty, similar to results reported in pointer-based sensitivity literature previously."
        thumbnail: boudaoud22.png
        banner: none.png
    - tr12:
        authors:
            - jspjut
            - fzhu
            - xhuang
            - yshou
            - bboudaoud
            - oshapira
            - mmcguire
        title: Experimental Augmented Reality User Experience
        conference: Tech Report
        conf-short: Tech Report
        month: February 10
        year: 2022
        date: 2022-02-10
        paper: https://arxiv.org/pdf/2202.06726
        alternate: https://arxiv.org/abs/2202.06726
        abstract: "Augmented Reality (AR) is an emerging field ripe for experimentation, especially when it comes to developing the kinds of applications and experiences that will drive mass adoption of the technology. While we aren't aware of any current consumer product that realize a wearable, wide Field of View (FoV), AR Head Mounted Display (HMD), such devices will certainly come. In order for these sophisticated, likely high-cost hardware products to succeed, it is important they provide a high quality user experience. To that end, we prototyped 4 experimental applications for wide FoV displays that will likely exist in the future. Given current AR HMD limitations, we used a AR simulator built on web technology and VR headsets to demonstrate these applications, allowing users and designers to peer into the future."
        thumbnail: spjut22.png
        banner: spjut22.png
    - tr11:
        authors:
            - eprashnani
            - ogallo
            - joohwankim
            - jspjut
            - psen
            - ifrosio
        title: "Noise-Aware Saliency Prediction for Videos with Incomplete Gaze Data"
        conference: Tech Report
        conf-short: Tech Report
        month: April 16
        year: 2021
        date: 2021-04-16
        paper: https://arxiv.org/pdf/2104.08038
        alternate: https://arxiv.org/abs/2104.08038
        abstract: "We tackle the problem of predicting saliency maps for videos of dynamic scenes. We note that the accuracy of the maps reconstructed from the gaze data of a fixed number of observers varies with the frame, as it depends on the content of the scene. This issue is particularly pressing when a limited number of observers are available. In such cases, directly minimizing the discrepancy between the predicted and measured saliency maps, as traditional deep-learning methods do, results in overfitting to the noisy data. We propose a noise-aware training (NAT) paradigm that quantifies and accounts for the uncertainty arising from frame-specific gaze data inaccuracy. We show that NAT is especially advantageous when limited training data is available, with experiments across different models, loss functions, and datasets. We also introduce a video game-based saliency dataset, with rich temporal semantics, and multiple gaze attractors per frame. The dataset and source code are available at https://github.com/NVlabs/NAT-saliency"
        thumbnail: prashnani21.png
        banner: prashnani21.png
    - tr10:
        authors:
            - zmajercik
            - amarrs
            - jspjut
            - mmcguire
        title: "Scaling Probe-Based Real-Time Dynamic Global Illumination for Production"
        conference: Tech Report
        conf-short: Tech Report
        month: Sep 22
        year: 2020
        date: 2020-09-22
        paper: https://arxiv.org/pdf/2009.10796
        alternate: https://arxiv.org/abs/2009.10796
        abstract: "We contribute several practical extensions to the probe based irradiance-field-with-visibility representation to improve image quality, constant and asymptotic performance, memory efficiency, and artist control. We developed these extensions in the process of incorporating the previous work into the global illumination solutions of the NVIDIA RTXGI SDK, the Unity and Unreal Engine 4 game engines, and proprietary engines for several commercial games. These extensions include: a single, intuitive tuning parameter (the 'self-shadow' bias); heuristics to speed transitions in the global illumination; reuse of irradiance data as prefiltered radiance for recursive glossy reflection; a probe state machine to prune work that will not affect the final image; and multiresolution cascaded volumes for large worlds."
        thumbnail: majercik20.png
        banner: majercik20.png
    - tr9:
        authors:
            - jspjut
            - bboudaoud
            - jonghyunkim
            - tgreer
            - ralbert
            - mstengel
            - kaksit
            - dluebke
        title: "Toward Standardized Classification of Foveated Displays"
        conference: Tech Report
        conf-short: Tech Report
        month: May 3
        year: 2019
        date: 2019-05-03
        paper: https://arxiv.org/pdf/1905.06229
        alternate: https://arxiv.org/abs/1905.06229
        abstract: "Emergent in the field of head mounted display design is a desire to leverage the limitations of the human visual system to reduce the computation, communication, and display workload in power and form-factor constrained systems. Fundamental to this reduced workload is the ability to match display resolution to the acuity of the human visual system, along with a resulting need to follow the gaze of the eye as it moves, a process referred to as foveation. A display that moves its content along with the eye may be called a Foveated Display, though this term is also commonly used to describe displays with non-uniform resolution that attempt to mimic human visual acuity. We therefore recommend a definition for the term Foveated Display that accepts both of these interpretations. Furthermore, we include a simplified model for human visual Acuity Distribution Functions (ADFs) at various levels of visual acuity, across wide fields of view and propose comparison of this ADF with the Resolution Distribution Function of a foveated display for evaluation of its resolution at a particular gaze direction. We also provide a taxonomy to allow the field to meaningfully compare and contrast various aspects of foveated displays in a display and optical technology-agnostic manner."
        thumbnail: spjutfdtr19.png
        banner: spjutfdtr19.png
    - tr8:
        authors:
            - kshkurko
            - tgrant
            - elb
            - dkopta
            - jspjut
            - evasiou
            - amallett
            - cyuksel
        title: "SimTrax: Simulation Infrastructure for Exploring Thousands of Cores"
        conference: Tech Report
        conf-short: Tech Report
        month: March 29
        year: 2018
        date: 2018-03-29
        paper: http://josef.spjut.me/pubs/shkurko18_tr.pdf
        abstract: "SimTRaX is a simulation infrastructure for simultaneous exploration of highly parallel accelerator architectures and how applications map to them. The infrastructure targets both cycle-accurate and functional simulation of architectures with thousands of simple cores that may share expensive computation and memory resources. A modified LLVM backend used to compile C++ programs for the simulated architecture allows the user to create custom instructions that access proposed special-purpose hardware and to debug and profile the applications being executed. The simulator models a full memory hierarchy including registers, local scratchpad RAM, shared caches, external memory channels, and DRAM main memory, leveraging the USIMM DRAM simulator to provide accurate dynamic latencies and power usage. SimTRaX provides a powerful and flexible infrastructure for exploring a class of extremely parallel architectures for parallel applications that are not easily simulated using existing simulators."
        thumbnail: shkurko18.png
        banner: shkurko18.png
    - tr7:
        authors:
        - clarson
        - jspjut
        - rknepper
        - rshepherd
        title: "OrbTouch: Recognizing Human Touch in Deformable Interfaces with Deep Neural Networks"
        conference: "Tech Report, arXiv:1706.02542"
        conf-short: Tech Report
        month: June
        year: 2017
        date: 2017-06-08
        paper: https://arxiv.org/abs/1706.02542
        thumbnail: clarson17.png
        banner: clarson17.png
    - tr6:
        authors:
        - jsung
        - skrupa
        - afishberg
        - jspjut
        title: An Approach to Data Prefetching Using 2-Dimensional Selection Criteria
        conference: "Tech Report, arXiv:1505.03899"
        conf-short: Tech Report
        month: May
        year: 2015
        date: 2015-05-01
        paper: http://arxiv.org/abs/1505.03899
        thumbnail: sung15.png
    - tr5:
        authors:
        - dhpark
        - abagaria
        - fhannan
        - estorm
        - jspjut
        title: "Sphynx: A Shared Instruction Cache Exporatory Study"
        conference: "Tech Report, arXiv:1412.1140"
        conf-short: Tech Report
        month: December 3 
        year: 2014
        date: 2014-12-03
        paper: http://arxiv.org/abs/1412.1140
        thumbnail: park14.png
        banner: park14.png
    - tr4:
        authors:
        - estorm
        - jspjut
        title: "A Time-to-Recache Case Study"
        conference: "Tech Report"
        month: March
        year: 2014
        date: 2014-03-01
        paper: http://josef.spjut.me/pubs/stormttr14.pdf
        thumbnail: storm14.png
    - tr3:
        authors:
        - acarter
        - mkorbel
        - pning
        - jspjut
        title: "Qualitative Cache Performance Analysis"
        conference: "Tech Report"
        month: September
        year: 2013
        date: 2013-09-01
        paper: http://josef.spjut.me/pubs/carterttr13.pdf
        thumbnail: carter13.png
    - tr2:
        authors:
        - jspjut
        - spugsley
        title: "Time to Recache: Measuring Memory Miss Behavior"
        conference: "Tech Report"
        month: September
        year: 2011
        date: 2011-09-01
        paper: http://josef.spjut.me/pubs/ttr11.pdf
        thumbnail: ttr11.png
    - tr1:
        authors:
        - dkopta
        - aek
        - tize
        - jspjut
        - elb
        - ald
        title: Fast, Effective BVH Updates for Dynamic Ray-Traced Scenes Using Tree Rotations
        conference: Tech Report, UUCS 11-002, University of Utah
        conf-short: Tech Report
        month: July 
        year: 2011
        date: 2011-07-01
        paper: https://pdfs.semanticscholar.org/c352/f679482dcea78e1abe0913b8e12d1c52ae5b.pdf
        thumbnail: kopta12.png
        banner: kopta12.png
---
name: Refereed Posters
hugoid: 11
urlid: pos
pubs:
    - p6:
        authors:
        - ziyangchen
        - mdogan
        - jspjut
        - kaksit
        title: "SpecTrack: Learned Multi-Rotation Tracking via Speckle Imaging"
        conference: SIGGRAPH Asia Poster
        conf-short: SIGGRAPH Asia Poster
        location: Tokyo
        month: December 3-6
        year: 2024
        date: 2024-12-03
        paper: https://arxiv.org/abs/2410.06028
        alternate: https://complightlab.com/publications/spec_track/
        thumbnail: chen24.png
        banner: none.png
        abstract: "Precision pose detection is increasingly demanded in fields such as personal fabrication, Virtual Reality (VR), and robotics due to its critical role in ensuring accurate positioning information. However, conventional vision-based systems used in these systems often struggle with achieving high precision and accuracy, particularly when dealing with complex environments or fast-moving objects. To address these limitations, we investigate Laser Speckle Imaging (LSI), an emerging optical tracking method that offers promising potential for improving pose estimation accuracy. Specifically, our proposed LSI-Based Tracking (SpecTrack) leverages the captures from a lensless camera and a retro-reflector marker with a coded aperture to achieve multi-axis rotational pose estimation with high precision. Our extensive trials using our in-house built testbed have shown that SpecTrack achieves an accuracy of 0.31{deg} (std=0.43{deg}), significantly outperforming state-of-the-art approaches and improving accuracy up to 200%."
    - p5:
        authors:
        - jspjut
        - bboudaoud
        - kbinaee
        - zmajercik
        - mmcguire
        - joohwankim
        title: "FirstPersonScience: Quantifying Psychophysics for First Person Shooter Tasks"
        conference: UCI Esports Conference
        conf-short: ESC
        location: Irvine
        month: October 10-12
        year: 2019
        date: 2019-10-10
        paper: http://josef.spjut.me/pubs/spjut19esc_paper.pdf
        alternate: https://uciesportsconference2019.sched.com/event/UQdr/posters-reception-heavy-hors-doeuvres-gallery
        thumbnail: spjut19-esc.png
        banner: spjut19-esc.png
        abstract: "In the emerging field of esports research, there is an increasing demand for quantitative results that can be used by players, coaches and analysts to make decisions and present meaningful commentary for spectators. We present FirstPersonScience, a software application intended to fill this need in the esports community by allowing scientists to design carefully controlled experiments and capture accurate results in the First Person Shooter esports genre. An experiment designer can control a variety of parameters including target motion, weapon configuration, 3D scene, frame rate, and latency. Furthermore, we validate this application through careful end-to-end latency analysis and provide a case study showing how it can be used to demonstrate the training effect of one user given repeated task performance."
    - p4:
        authors:
        - joohwankim
        - jspjut
        - mmcguire
        - zmajercik
        - bboudaoud
        - ralbert
        - dluebke
        title: "Esports Arms Race: Latency and Refresh Rate for Competitive Gaming Tasks"
        conference: Vision Science Society
        conf-short: VSS
        location: St. Pete Beach
        month: May 17-22
        year: 2019
        date: 2019-05-17
        paper: https://www.visionsciences.org/programs/VSS_2019_Abstracts.pdf
        thumbnail: kim19-vss.png
        banner: kim19-vss.png
        abstract: "In the world of esports (competitive video games), hardware and software configurations are optimized for winning. In many games this means minimizing latency ('I see you before you see me') and maximizing refresh rate ('I see your move more accurately'). Most esports athletes and competitive players ensure this by using high-end hardware (computers, monitors, and GPUs) while turning off superfluous in-game graphics features. By doing so, one can demonstrate the competitive benefit of modern display technologies. We conducted two user studies that compare esports performance using common display settings. We conclude that 240 hz, today's highest-speed display technology, provides a competitive advantage."
    - p3:
        authors:
        - mjalal
        - jspjut
        - bboudaoud
        - mbetke
        title: Large-scale Synthetic Domain Randomized 6DoF Object Pose Estimation Dataset
        conference: New England Computer Vision Workshop
        conf-short: NECV
        location: Boston
        month: November 26
        year: 2018
        date: 2018-11-26
        paper: http://josef.spjut.me/pubs/jalal18_poster.pdf
        thumbnail: jalal18.png
        banner: jalal18.png
    - p2:
        authors:
        - dkopta
        - jspjut
        - elb
        title: Grid-Based Ray Tracing for a Parallel Computing Architecture
        conference: High Performance Graphics (HPG'09)
        conf-short: HPG
        location: New Orleans
        month: August 1-3
        year: 2009
        date: 2009-08-01
        paper: http://josef.spjut.me/pubs/HPG09_poster.pdf
        thumbnail: koptaposter09.png
    - p1:
        authors:
        - dkopta
        - jspjut
        - elb 
        - sparker
        title: Comparing Incoherent Ray Performance of TRaX vs. Manta
        conference: IEEE Symposium on Interactive Ray Tracing (RT08)
        conf-short: RT
        month: August 9-10
        year: 2008
        date: 2008-08-09
        paper: http://josef.spjut.me/pubs/kopta_rt08.pdf
        alternate: http://josef.spjut.me/pubs/koptaGradPoster2009.pdf
        thumbnail: koptaposter08.png
        abstract: TRaX (Threaded Ray eXecution) is a highly parallel multi-threaded, multi-core processor architecture designed for real-time ray tracing. One motivation behind TRaX is to accelerate single-ray performance instead of relying on ray-packets in SIMD mode to boost throughput, which can fail as packets become incoherent. To evaluate the effectiveness of this approach we implement a path tracer on the TRaX simulator and measure performance as the secondary rays become less coherent. We are able to show that TRaX exhibits only minor slowdown on highly incoherent rays compared to a well-optimized SIMD-packet based path tracer which suffers significant slowdown as rays become incoherent.
---
name: Unpublished
hugoid: -1
urlid: unpub
pubs:
    - up6:
        authors:
        - joohwankim
        - bboudaoud
        - bwatson
        - amadhusudan
        title: esports research
        year: 2024
        date: 2024-12-31
    - up5:
        authors:
        - joohwankim
        - bboudaoud
        - bwatson
        - apatney
        - rbrown
        title: esports research
        year: 2022
        date: 2022-12-31
    - up4:
        authors:
        - joohwankim
        - bboudaoud
        - mmcguire
        title: esports research
        year: 2021
        date: 2021-03-31
    - tr10:
        authors:
        - nkalavakonda
        - jspjut
        - bboudaoud
        title: TrackNN
        year: 2018
        date: 2018-11-28
    - up3:
        authors:
        - dluebke
        - jtw
        - tgreer
        - mmcguire
        - balfieri
        title: NVIDIA ongoing
        year: 2018
        date: 2018-08-31
    - up2:
        authors:
        - jspjut
        - taila
        - tkarras
        - slaine
        - dluebke
        title: NVIDIA 2015
        year: 2015
        date: 2015-05-30
    - up1:
        authors:
        - mparker
        title: NVIDIA 2013
        year: 2013
        date: 2013-09-01
    - up0:
        authors:
        - jspjut
        - fvahid
        - dsheldon
        - ssirowy
        - rlysecky
        title: UCR
        year: 2006
        date: 2006-06-20
...






